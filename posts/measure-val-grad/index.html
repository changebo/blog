<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <title>Measure-Valued Gradient Estimator and Application to Variational Autoencoder</title>
  
  <meta name="description" content="Measure-Valued Gradient Estimator and Application to Variational Autoencoder">
  
  <meta name="image" content="https://bochang.me/blog/posts/measure-val-grad/norm_mu.png">
  
  <meta name="keywords" content="Monte Carlo Gradient Estimator, Variational Autoencoders, Measure-Valued Gradient Estimator, Score Function Estimator, REINFORCE Estimator, Pathwise estimator, Reparametrization Trick">
  
  <meta itemprop="name" content="Measure-Valued Gradient Estimator and Application to Variational Autoencoder">
  <meta itemprop="description" content="Measure-Valued Gradient Estimator and Application to Variational Autoencoder">
  
  <meta itemprop="image" content="https://bochang.me/blog/posts/measure-val-grad/norm_mu.png">
  
  <meta name="og:title" content="Measure-Valued Gradient Estimator and Application to Variational Autoencoder">
  <meta name="og:description" content="Measure-Valued Gradient Estimator and Application to Variational Autoencoder">
  
  <meta name="og:image" content="https://bochang.me/blog/posts/measure-val-grad/norm_mu.png">
  <meta name="og:url" content="https://bochang.me/blog/posts/measure-val-grad/">
  <meta name="og:site_name" content="Measure-Valued Gradient Estimator and Application to Variational Autoencoder">
  <meta name="og:type" content="article">
  
  <meta name="article:tag" content="machine learning ">
  <link rel="stylesheet" type="text/css" href="https://bochang.me/blog/css/style.css">
  <link rel="icon" type="image/png" href="https://bochang.me/blog/icons/dice-16x16.png" sizes="16x16">
  <link rel="icon" type="image/png" href="https://bochang.me/blog/icons/dice-32x32.png" sizes="32x32">  
</head>

<body>
  <header>
    
    <a href="https://bochang.me/blog/" style="float: left;color:#ff3b30;">Bo&#39;s Blog</a>
    
    <a href="https://bochang.me/" style="color:#777;">&nbsp;&nbsp;About</a>
    &nbsp;&nbsp;
    
    
    <script type="application/ld+json">
    
    {
      "@context": "https://schema.org",
      "@type": "BlogPosting",
      "headline": "Measure-Valued Gradient Estimator and Application to Variational Autoencoder",
      "image": "https://bochang.me/blog/posts/measure-val-grad/norm_mu.png",
      "datePublished": "2020-03-07T00:00:00Z",
      "dateModified": "2020-03-07T00:00:00Z",
      "author": {
        "@type": "Person",
        "name": "Bo Chang",
        "url": "https://bochang.me"
      },
      "publisher": {
        "@type": "Organization",
        "name": "Bo's Blog",
        "url": "https://bochang.me/blog/",
        "logo": "https://bochang.me/blog/icons/dice-32x32.png"
      },
      "mainEntityOfPage": { "@type": "WebPage" },      
      "description": "In machine learning, the gradient estimation problem lies at the core of various problems. Mohamed et al. (2019) give a comprehensive survey of this topic, from which I learned an intriguing approach called the measure-valued gradient estimator. In this post, we give a brief review of the measure-valued gradient estimator and use it to train a variational autoencoder.\n1. Monte Carlo gradient estimation Given a random variable $\\boldsymbol{x} \\in \\mathbb{R}^d$, its density function $p(\\boldsymbol{x}; \\boldsymbol\\theta)$ parametrized by $\\boldsymbol\\theta \\in \\Theta \\subset \\mathbb{R}^m$, and a function $f: \\mathbb{R}^d \\to \\mathbb{R}$, the problem of gradient esitmation pertains to the gradient of the expectation of $f(\\boldsymbol{x})$ with respect to the parameters $\\boldsymbol\\theta$: $$ \\boldsymbol\\eta := \\nabla_\\boldsymbol\\theta \\mathbb{E}_{\\boldsymbol{x} \\sim p(\\boldsymbol{x}; \\boldsymbol\\theta)} f(\\boldsymbol{x}).",
      "keywords": ["Monte", "Carlo", "Gradient", "Estimator,", "Variational", "Autoencoders,", "Measure-Valued", "Gradient", "Estimator,", "Score", "Function", "Estimator,", "REINFORCE", "Estimator,", "Pathwise", "estimator,", "Reparametrization", "Trick"]
    }
    
    </script>    
  </header>
<div class="content">
  <h1>Measure-Valued Gradient Estimator and Application to Variational Autoencoder</h1>
  <p>
  <aside>tags: <a href="/blog/tags/machine-learning/">machine learning</a></a>&nbsp;&nbsp;&nbsp;</aside>
  </p>
  <p><p>In machine learning, the gradient estimation problem lies at the core of various problems.
Mohamed et al. (2019) give a comprehensive survey of this topic, from which I learned an intriguing approach called the <em>measure-valued gradient estimator</em>.
In this post, we give a brief review of the measure-valued gradient estimator and use it to train a variational autoencoder.</p>
<h2 id="1-monte-carlo-gradient-estimation">1. Monte Carlo gradient estimation</h2>
<p>Given a random variable $\boldsymbol{x} \in \mathbb{R}^d$, its density function $p(\boldsymbol{x}; \boldsymbol\theta)$ parametrized by $\boldsymbol\theta \in \Theta \subset \mathbb{R}^m$, and a function $f: \mathbb{R}^d \to \mathbb{R}$, the problem of gradient esitmation pertains to the gradient of the expectation of $f(\boldsymbol{x})$ with respect to the parameters $\boldsymbol\theta$:
$$
\boldsymbol\eta := \nabla_\boldsymbol\theta \mathbb{E}_{\boldsymbol{x} \sim p(\boldsymbol{x}; \boldsymbol\theta)} f(\boldsymbol{x}).
$$
Estimating this quantity is crucial to the policy gradient methods in reinforcement learning, learning the approximate posterior distribution in variational inference, and sensitivity analysis in other fields.</p>
<p>Monte Carlo gradient estimation methods try to estimate $\boldsymbol\eta$ using Monte Carlo samples.
There are two well-known methods: the <em>score function estimator</em> and the <em>pathwise estimator</em>.
The <em>score function estimator</em> is also known as the <em>REINFORCE estimator</em>.
It rewrites $\boldsymbol\eta$ using the &ldquo;log-derivative trick&rdquo;:
\begin{align}
\boldsymbol\eta &amp;=
\nabla_\boldsymbol\theta \mathbb{E}_{\boldsymbol{x} \sim p(\boldsymbol{x}; \boldsymbol\theta)} f(\boldsymbol{x})
\newline
&amp;= \nabla_\boldsymbol\theta \int f(\boldsymbol{x}) p(\boldsymbol{x}; \boldsymbol\theta) \mathrm{d} \boldsymbol{x}
\newline
&amp;= \int f(\boldsymbol{x}) \nabla_\theta p(\boldsymbol{x}; \boldsymbol\theta) \mathrm{d} \boldsymbol{x}
\newline
&amp;= \int f(\boldsymbol{x}) p(\boldsymbol{x}; \boldsymbol\theta) \nabla_\boldsymbol\theta \log p(\boldsymbol{x}; \boldsymbol\theta) \mathrm{d} \boldsymbol{x}
\newline
&amp;= \mathbb{E}_{\boldsymbol{x} \sim p(\boldsymbol{x}; \boldsymbol\theta)} [ f(\boldsymbol{x}) \nabla_\boldsymbol\theta \log p(\boldsymbol{x}; \boldsymbol\theta)].
\end{align}
It is obvious that this expectation can be estimated by the sample mean:
$$
\widehat{\boldsymbol\eta} = \frac{1}{k} \sum_{i=1}^k f(\widehat{\boldsymbol{x}}_i) \nabla_\boldsymbol\theta \log p(\widehat{\boldsymbol{x}}_i; \boldsymbol\theta),
\quad \widehat{\boldsymbol{x}}_i \overset{\mathrm{iid}}{\sim} p(\boldsymbol{x}; \boldsymbol\theta).
$$
Another commonly used estimator is the <em>pathwise estimator</em>, also known as the <em>reparametrization trick</em>. The idea is to rewrite $\boldsymbol{x}$ as a function of another random variable following a base distribution.
Specifically, if $\boldsymbol{x} \overset{d}{=} g(\boldsymbol\epsilon; \boldsymbol\theta)$, where $\boldsymbol\epsilon \sim p(\boldsymbol\epsilon)$ that does not depend on $\boldsymbol\theta$, then
\begin{align}
\boldsymbol\eta &amp;=
\nabla_\boldsymbol\theta \mathbb{E}_{\boldsymbol{x} \sim p(\boldsymbol{x}; \boldsymbol\theta)} f(\boldsymbol{x})
\newline
&amp;= \nabla_\boldsymbol\theta \int p(\boldsymbol{x}; \boldsymbol\theta) f(\boldsymbol{x}) \mathrm{d} \boldsymbol{x}
\newline
&amp;= \nabla_\boldsymbol\theta \int p(\boldsymbol\epsilon) f(g(\boldsymbol\epsilon; \boldsymbol\theta)) \mathrm{d} \boldsymbol\epsilon
\newline
&amp;= \int p(\boldsymbol\epsilon) \nabla_\boldsymbol\theta f(g(\boldsymbol\epsilon; \boldsymbol\theta)) \mathrm{d} \boldsymbol\epsilon
\newline
&amp;= \mathbb{E}_{\boldsymbol\epsilon \sim p(\boldsymbol\epsilon)} [ \nabla_\boldsymbol\theta f(g(\boldsymbol\epsilon; \boldsymbol\theta)) ].
\end{align}
Again, the above quantity can be estimated by Monte Carlo samples from the base distribution $p(\boldsymbol\epsilon)$:
$$
\widehat{\boldsymbol\eta} = \frac{1}{k} \sum_{i=1}^k \nabla_\boldsymbol\theta f(g(\widehat{\boldsymbol\epsilon}_i; \boldsymbol\theta)),
\quad \widehat{\boldsymbol\epsilon}_i \overset{\mathrm{iid}}{\sim} p(\boldsymbol\epsilon).
$$</p>
<p>We refer the interested readers to Mohamed et al. (2019) for a more detailed exposition of the two estimators.</p>
<h2 id="2-measure-valued-gradient-estimator">2. Measure-valued gradient estimator</h2>
<p>There exists another estimator that is less familiar to the machine learning community called the <em>measure-valued gradient estimator</em>.
We first define the estimator, then provide two simple examples.
Finally, the pros and cons of it are briefly discussed.</p>
<h3 id="21-definition">2.1. Definition</h3>
<p>We only consider a distribution with a scalar parameter $\theta \in \mathbb{R}$ for now.
It can be shown that the derivative of the density $\nabla_\theta p(\boldsymbol{x}; \theta)$ can always be decomposed into the difference of two densities multiplied by a constant:
$$
\nabla_\theta p(\boldsymbol{x}; \theta) = c_\theta \left(p^+ (\boldsymbol{x}; \theta) - p^- (\boldsymbol{x}; \theta) \right),
$$
where $p^+$ and $p^-$ are probability densities, referred to as the positive and negative components, respectively, and $c_\theta \in \mathbb{R}$ is a constant.
The triplet $(c_\theta, p^+, p^-)$ is called the <em>weak derivative</em> of $p(\boldsymbol{x}; \theta)$.
This decomposition applies to discrete distributions as well.</p>
<p>Using the weak derivative, the gradient $\eta$ can be rewritten as follows:
\begin{align}
\eta
&amp;= \nabla_{\theta} \mathbb{E}_{\boldsymbol{x} \sim p(\boldsymbol{x}; \theta)} f(\boldsymbol{x})
\newline
&amp;= \nabla_\theta \int f(\boldsymbol{x}) p(\boldsymbol{x}; \theta) \mathrm{d} \boldsymbol{x}
\newline
&amp;= \int f(\boldsymbol{x}) \nabla_\theta p(\boldsymbol{x}; \theta) \mathrm{d} \boldsymbol{x}
\newline
&amp;= c_\theta \left( \int f(\boldsymbol{x}) p^+ (\boldsymbol{x}; \theta) \mathrm{d} \boldsymbol{x} - \int f(\boldsymbol{x}) p^- (\boldsymbol{x}; \theta) \mathrm{d} \boldsymbol{x} \right)
\newline
&amp;= c_\theta \left( \mathbb{E}_{\boldsymbol{x}^+ \sim p^+(\boldsymbol{x}; \theta)} f(\boldsymbol{x}^+) - \mathbb{E}_{\boldsymbol{x}^- \sim p^-(\boldsymbol{x}; \theta)} f(\boldsymbol{x}^-)  \right).
\end{align}</p>
<p>The corresponding estimator is
$$
\widehat{\eta} = \frac{c_\theta}{k} \sum_{i=1}^k \left[ f(\widehat{\boldsymbol{x}}_i^+) - f(\widehat{\boldsymbol{x}}_i^-) \right],
\quad \widehat{\boldsymbol{x}}_i^+ \overset{\mathrm{iid}}{\sim} p^+(\boldsymbol{x}; \theta) \mbox{ and } \widehat{\boldsymbol{x}}_i^- \overset{\mathrm{iid}}{\sim} p^-(\boldsymbol{x}; \theta).
$$</p>
<p>Note that $\boldsymbol{x}_i^+$ and $\boldsymbol{x}_i^-$ do not need to be independent. In fact, it is a common trick to make $f(\boldsymbol{x}_i^+)$ and $f(\boldsymbol{x}_i^-)$ positively correlated in order to reduce the variance of the estimator; this is known as <em>coupling</em>.</p>
<h3 id="22-two-examples">2.2. Two examples</h3>
<p>Before introducing the examples, we first review a few relevant distribution families and their density functions.</p>
<ul>
<li>
<p><a href="https://en.wikipedia.org/wiki/Normal_distribution">Normal distribution</a> $\mathcal{N}(\mu, \sigma^2)$:
$$
p_{\mathcal{N}}(x; \mu, \sigma) = \frac{1}{\sigma \sqrt{2\pi}} \exp\left(- \frac{(x - \mu)^2}{2\sigma^2}\right).
$$</p>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Weibull_distribution">Weibull distribution</a> $\mathcal{W}(\lambda, k)$:
$$
p_{\mathcal{W}}(x; \lambda, k)
= \frac{k}{\lambda} \left( \frac{x}{\lambda} \right)^{k-1} \exp \left( -\left( \frac{x}{\lambda} \right)^k \right) \mathbb{I}_{x \geq 0}.
$$</p>
</li>
<li>
<p>Double-sided <a href="https://en.wikipedia.org/wiki/Maxwell%E2%80%93Boltzmann_distribution">Maxwell distribution</a> $\mathcal{M}(\mu, \sigma^2)$:
$$
p_{\mathcal{M}}(x; \mu, \sigma) =
\frac{(x-\mu)^2}{\sigma^3\sqrt{2 \pi}} \exp\left( -\frac{(x-\mu)^2}{2 \sigma^2} \right).
$$</p>
</li>
</ul>
<p><strong>Example 1</strong> (Normal distribution with respect to the location parameter).
Consider the derivative of the density function of $\mathcal{N}(\mu, \sigma^2)$ with respect to $\mu$.
We would like to show that
\begin{equation}
\nabla_\mu p_{\mathcal{N}}(x; \mu, \sigma) = c_\mu \left(p^+ (x; \mu, \sigma) - p^- (x; \mu, \sigma) \right),
\label{eq:gaussian-mean}
\tag{1}
\end{equation}
where</p>
<ul>
<li>$c_\mu = (\sigma \sqrt{2\pi})^{-1} $;</li>
<li>$p^+$ is the density function of $\mu + \sigma \mathcal{W}(\lambda=\sqrt{2}, k=2)$;</li>
<li>$p^-$ is the density function of $\mu - \sigma \mathcal{W}(\lambda=\sqrt{2}, k=2)$.</li>
</ul>
<p>The notation $\mu \pm \sigma \mathcal{W}(\lambda=\sqrt{2}, k=2)$ represents a random variable $\mu \pm \sigma Y$, where $Y \sim \mathcal{W}(\lambda=\sqrt{2}, k=2)$, the Weibull distribution.</p>
<p><strong>Proof.</strong> For the left-hand side of Equation \ref{eq:gaussian-mean}, basic calculus shows that
$$
\nabla_{\mu}
p_{\mathcal{N}}(x; \mu, \sigma) = \frac{x-\mu}{\sigma^3 \sqrt{2\pi}} \exp\left(- \frac{(x - \mu)^2}{2\sigma^2}\right).
$$</p>
<p>Recall that the density function of a Weibull random variable $\mathcal{W}(\lambda=\sqrt{2}, k=2)$ is
$$
p_\mathcal{W}(x; \lambda=\sqrt{2}, k=2) = x \exp\left( -\frac{x^2}{2} \right) \mathbb{I}_{x \geq 0}.
$$
Using the <a href="https://en.wikipedia.org/wiki/Probability_density_function#Function_of_random_variables_and_change_of_variables_in_the_probability_density_function">change of variables formula</a>, we have
$$
p^+(x; \mu, \sigma) = \frac{x-\mu}{\sigma^2} \exp\left( -\frac{(x-\mu)^2}{2\sigma^2} \right) \mathbb{I}_{x \geq \mu}
$$
and
$$
p^-(x; \mu, \sigma) = -\frac{x-\mu}{\sigma^2} \exp\left( -\frac{(x-\mu)^2}{2\sigma^2} \right) \mathbb{I}_{x \leq \mu}.
$$
Therefore, the right-hand side of Equation \ref{eq:gaussian-mean} is</p>
<p>$$
c_\mu \left(p^+ (x; \mu, \sigma) - p^- (x; \mu, \sigma) \right)=
\frac{x-\mu}{\sigma^3 \sqrt{2\pi}} \exp\left(- \frac{(x - \mu)^2}{2\sigma^2}\right),
$$
which equals the left-hand side.</p>
<p>Figure 1 gives an illustration of this example with $\mu=\sigma=1$.
The first row shows the density function $p_{\mathcal{N}}(x; \mu, \sigma)$ (the solid line) and how it changes when $\mu$ increases by 0.1 (the dashed line); the difference (divided by 0.1) is approximately the gradient of interest.
The second row is the gradient $\nabla_{\mu} p_{\mathcal{N}}(x; \mu, \sigma)$.
The last two rows are the positive and negative components multiplied by the constant $c_\mu$, respectively; it indicates that the difference between them matches the curve in the second row.</p>
<figure>
    <img src="norm_mu.png" alt="Derivative of a normal density with respect to the location parameter." width="500"/>
    <figcaption>Figure 1: Derivative of a normal density with respect to the location parameter.</figcaption>
</figure>
<p><strong>Example 2</strong> (Normal distribution with respect to the scale parameter).
Consider the derivative of the density function of $\mathcal{N}(\mu, \sigma^2)$ with respect to $\sigma$.
We would like to show that
\begin{equation}
\nabla_\sigma p_{\mathcal{N}}(x; \mu, \sigma) = c_\sigma \left(p^+ (x; \mu, \sigma) - p^- (x; \mu, \sigma) \right),
\label{eq:gaussian-std}
\tag{2}
\end{equation}
where</p>
<ul>
<li>$c_\sigma = \sigma^{-1}$;</li>
<li>$p^+ = p_\mathcal{M}(x; \mu, \sigma)$;</li>
<li>$p^-= p_\mathcal{N}(x; \mu, \sigma)$.</li>
</ul>
<p><strong>Proof.</strong> The proof is similar to that of Example 1 using basic calculus:
\begin{align}
&amp;\quad \nabla_{\sigma}
p_{\mathcal{N}}(x; \mu, \sigma)
\newline
&amp; = \frac{1}{\sigma} \left[ \frac{(x-\mu)^2}{\sigma^3 \sqrt{2\pi}} \exp\left(- \frac{(x - \mu)^2}{2\sigma^2}\right) - \frac{1}{\sigma \sqrt{2\pi}} \exp\left(- \frac{(x - \mu)^2}{2\sigma^2}\right) \right]
\newline
&amp; = \sigma^{-1} \left( p_\mathcal{M}(x; \mu, \sigma) - p_\mathcal{N}(x; \mu, \sigma) \right).
\end{align}</p>
<p>Figure 2 is the corresponding illustration.</p>
<figure>
    <img src="norm_sigma.png" alt="Derivative of a normal density with respect to the scale parameter." width="500"/>
    <figcaption>Figure 2: Derivative of a normal density with respect to the scale parameter.</figcaption>
</figure>
<h3 id="23-pros-and-cons">2.3. Pros and cons</h3>
<p>The advantage of the measure-valued gradient estimator is its flexibility.
It is applicable to both continuous and discrete random variables.
Also, unlike the pathwise estimator, it does not assume the function $f$ to be differentiable.
Furthermore, there are distributions where the measure-valued gradient estimator is applicable, but the score function estimator is not, for example, the uniform distribution $\mathcal{U}(0, \theta)$.</p>
<p>One major disadvantage is its computational cost.
The estimator only applies to a single parameter.
For distributions with many parameters, it requires two forward passes of the function $f$ for each parameter, which might be computationally prohibitive.</p>
<h2 id="3-application-to-variational-autoencoder">3. Application to variational autoencoder</h2>
<p>As mentioned before, the pathwise estimator or reparametrization trick is commonly used in variation inference, in particular, the variational autoencoder (VAE).
The objective of VAE is to maximize the <em>evidence lower bound</em> (ELBO),
$$
\mathcal{L} = \mathbb{E}_{\boldsymbol{z} \sim q_{\boldsymbol\phi}(\boldsymbol{z} | \boldsymbol{x})}
\log ( p_{\boldsymbol\theta}(\boldsymbol{x} | \boldsymbol{z})  ) - D_{\mathrm{KL}} ( q_{\boldsymbol\phi}(\boldsymbol{z} | \boldsymbol{x}) \parallel p(\boldsymbol{z}) ),
$$
where $D_{\mathrm{KL}}$ denotes the <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback–Leibler divergence</a>;
$\boldsymbol{x}$ and $\boldsymbol{z}$ are the observed and latent variables, respectively;
$p(\boldsymbol{z})$ is the prior distribution of $\boldsymbol{z}$;
$p_{\boldsymbol\theta}(\boldsymbol{x} | \boldsymbol{z})$ is the generative distribution and is implemented by a decoding network parametrized by $\boldsymbol\theta$;
$q_{\boldsymbol\phi}(\boldsymbol{z} | \boldsymbol{x})$ is the variational distribution and is implemented by an encoding network parametrized by $\boldsymbol\phi$.</p>
<p>Given a sample $\boldsymbol{z} \sim q_{\boldsymbol\phi}(\boldsymbol{z} | \boldsymbol{x})$, the gradient with respect to the decoder parameters $\nabla_{\boldsymbol\theta} \mathcal{L}$ can be easily obtained by automatic differentiation.
Furthermore, if $p(\boldsymbol{z})$ and $q_{\boldsymbol\phi}(\boldsymbol{z} | \boldsymbol{x})$ are both diagonal Gaussians, the KL divergence has a closed-form expression, and $\nabla_{\boldsymbol\phi} D_{\mathrm{KL}} ( q_{\boldsymbol\phi}(\boldsymbol{z} | \boldsymbol{x}) \parallel p(\boldsymbol{z}) )$ can also be computed via automatic differentiation.
However, to estimate $\nabla_{\boldsymbol\phi} \mathbb{E}_{\boldsymbol{z} \sim q_{\boldsymbol\phi}(\boldsymbol{z} | \boldsymbol{x})} \log ( p_{\boldsymbol\theta}(\boldsymbol{x} | \boldsymbol{z})  )$, a Monte Carlo gradient estimator is necessary.
In this section, we demonstrate how to estimate it using the measure-valued gradient estimator.
The code is adapted from the <a href="https://github.com/pytorch/examples/tree/master/vae">PyTorch VAE example</a>.</p>
<p>We first define the <code>VAE</code> module. The encoder and decoder are both two-layer fully connected networks, with default arguments <code>args.hidden_dim = 400</code> and <code>args.z_dim = 20</code>.
The only difference from the original code is the line <code>z = z.detach()</code> in <code>reparameterize()</code>. This is to prevent the gradient $\nabla_{\boldsymbol\phi} \mathbb{E}_{\boldsymbol{z} \sim q_{\boldsymbol\phi}(\boldsymbol{z} | \boldsymbol{x})} \log ( p_{\boldsymbol\theta}(\boldsymbol{x} | \boldsymbol{z}) )$ from flowing into the encoder network.</p>
<div data-gist-id="b28902f41f8d4500c599dad15f1fc278" data-gist-line="69-98"></div>
<p>Assuming $p_{\boldsymbol\theta}(\boldsymbol{x} | \boldsymbol{z})$ is a Bernoulli distribution,  $\log p_{\boldsymbol\theta}(\boldsymbol{x} | \boldsymbol{z})$ is the binary cross entropy function and it is the integrand.</p>
<div data-gist-id="b28902f41f8d4500c599dad15f1fc278" data-gist-line="101-107"></div>
<p>Next, we need to be able to sample from the Weibull distribution and double-sided Maxwell distribution.
PyTorch has a built-in Weibull distribution class, and we can directly sample from an instance of that class.
For the double-sided Maxwell distribution, we can use the following property to sample from $\mathcal{M}(0, 1)$:</p>
<blockquote>
<p>If $X \sim \mathrm{Bernoulli}(1/2)$, $Y \sim \mathrm{Gamma}(3/2, 1/2)$, and $X$ and $Y$ are independent, then $(2X - 1) \sqrt{Y} \sim \mathcal{M}(0, 1)$.</p>
</blockquote>
<div data-gist-id="b28902f41f8d4500c599dad15f1fc278" data-gist-line="110-126"></div>
<p>Now we are ready to introduce the most crucial function <code>get_mu_std_grad()</code>. It returns the estimated gradient of $\mathbb{E}_{\boldsymbol{z} \sim q_{\boldsymbol\phi}(\boldsymbol{z} | \boldsymbol{x})} \log ( p_{\boldsymbol\theta}(\boldsymbol{x} | \boldsymbol{z}) )$ with respect to <code>mu</code> and <code>std</code>, the output of <code>encode()</code> in the <code>VAE</code> class.</p>
<p>The idea is to draw two samples <code>z1</code> and <code>z2</code> from the variational distribution first.
Then, we loop through all the latent dimensions; in the $i$-th iteration, <code>z1</code> and <code>z2</code> are cloned to <code>z1_copy</code> and <code>z2_copy</code>, then the $i$-th elements of <code>z1_copy</code> and <code>z2_copy</code> are substituted with samples from $p^+$ and $p^-$, respectively.
Finally, the updated <code>z1_copy</code> and <code>z2_copy</code> are passed to the function <code>f_integrand</code>, and the difference divided by the constant is the resulting gradient estimate for the $i$-th parameter.</p>
<p>It is worth mentioning that when estimating the gradient with respect to the standard deviation $\sigma$, the two samples from $\mathcal{M}(x; \mu, \sigma)$ and $\mathcal{N}(x; \mu, \sigma)$ are not independent.
We first draw a sample from the positive component
$\hat{x}^+ \sim \mathcal{M}(x; \mu, \sigma)$,
then draw a uniform sample $\hat{u} \sim \mathcal{U}(0, 1)$,
finally set $\hat{x}^- := \hat{u} \cdot \hat{x}^+$.
It can be shown that $\hat{x}^- \sim \mathcal{N}(x; \mu, \sigma)$, the negative component.
This is a variance reduction method known as the Maxwell-Gaussian coupling.</p>
<div data-gist-id="b28902f41f8d4500c599dad15f1fc278" data-gist-line="129-168"></div>
<p>Finally, everything is put together to the <code>train()</code> function.
The gradients of the decoder come from the binary cross-entropy loss; the gradients of the encoder come from two sources: the KL divergence and the measure-valued gradient estimator.</p>
<div data-gist-id="b28902f41f8d4500c599dad15f1fc278" data-gist-line="171-196"></div>
<p>Complete code can be found in the next section.</p>
<p>Figures 3 and 4 show the reconstructed images and the generated images with a model trained for 10 epochs.
Qualitatively, the results seem reasonable.</p>
<figure>
    <img src="reconstruction_10.png" alt="Reconstruction" width="300"/>
    <figcaption>Figure 3: Reconstructed images after 10 epochs.</figcaption>
</figure>
<figure>
    <img src="sample_10.png" alt="Sample" width="300"/>
    <figcaption>Figure 4: Generated images after 10 epochs.</figcaption>
</figure>
<h2 id="4-complete-code">4. Complete code</h2>
<script type="application/javascript" src="https://gist.github.com/changebo/b28902f41f8d4500c599dad15f1fc278.js"></script>

<h2 id="references">References</h2>
<ul>
<li>Mohamed, S., Rosca, M., Figurnov, M., &amp; Mnih, A. (2019). Monte Carlo gradient estimation in machine learning. arXiv preprint arXiv:1906.10652.</li>
</ul>
<script
  type="text/javascript"
  src="https://cdn.jsdelivr.net/npm/gist-embed@1.0.3/dist/gist-embed.min.js"
></script> 
</p>
</div>


<p>Written on Mar 7, 2020.</p>

<footer>
	<p>&copy; 2020 All rights reserved.</p>
</footer>
</body>
</html>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { fonts: ["TeX"] }
  });
</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-129064600-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
