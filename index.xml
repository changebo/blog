<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bo&#39;s Blog</title>
    <link>https://bochang.me/blog/</link>
    <description>Recent content on Bo&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 08 Dec 2018 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://bochang.me/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Stochastic Bandits and UCB Algorithm</title>
      <link>https://bochang.me/blog/posts/bandits/</link>
      <pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://bochang.me/blog/posts/bandits/</guid>
      <description>

&lt;p&gt;In our recent paper &lt;em&gt;Vine Copula Structure Learning via Monte Carlo Tree Search&lt;/em&gt; &lt;small&gt;(under review at AISTATS 2019)&lt;/small&gt;, we apply the UCT &lt;small&gt;(Upper Confidence bounds applied to Trees)&lt;/small&gt; algorithm to find an approximate solution to an NP-hard structure learning problem in statistics.
The UCT algorithm is based on the UCB1 &lt;small&gt;(Upper Confidence Bound)&lt;/small&gt;  algorithm for the stochastic bandit problem.&lt;/p&gt;

&lt;p&gt;Thankfully, I audited &lt;a href=&#34;https://www.cs.ubc.ca/~nickhar/&#34;&gt;Prof. Nick Harvey&lt;/a&gt;&amp;rsquo;s &lt;a href=&#34;https://www.cs.ubc.ca/~nickhar/F18-531/&#34;&gt;learning theory course&lt;/a&gt; this semester.
In one lecture, he gave a remarkably clear exposition of the multi-armed bandit problem and algorithms.
It deepened my understanding of the theoretical properties of the UCB1 algorithm.
This blog post is largely a transcription of the lecture; it gives an overview of the regret bound analysis of the explore-first algorithm and UCB1 algorithm. The material is also based on the first chapter of Slivkins (2017).&lt;/p&gt;

&lt;h2 id=&#34;1-problem-formulation&#34;&gt;1. Problem formulation&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&#34;https://en.wikipedia.org/wiki/Multi-armed_bandit&#34;&gt;multi-armed bandit problem&lt;/a&gt; has many practical applications including clinical trials, financial portfolio design, and online advertising.
The name comes from imagining a gambler at a row of slot machines &lt;small&gt;(sometimes known as &amp;ldquo;one-armed bandits&amp;rdquo;)&lt;/small&gt;, each with a lever.
In each round, the gambler picks a machine to play, then the reward for the chosen machine is observed.
The objective of the gambler is to maximize the sum of rewards earned through a sequence of lever pulls.
In the rest of the post, we use the term &amp;ldquo;arm&amp;rdquo; as a synonym for a slot machine.&lt;/p&gt;

&lt;p&gt;In this post, we focus on the &lt;strong&gt;stochastic bandit problem&lt;/strong&gt;, where the rewards for each arm are i.i.d. from a probability distribution specific to that arm.
Another variant of the multi-armed bandit problem is called the &lt;strong&gt;adversarial bandit problem&lt;/strong&gt;, where an adversary chooses the reward for each arm while the player chooses an arm.&lt;/p&gt;

&lt;p&gt;The crucial tradeoff the gambler faces is between &lt;strong&gt;exploration&lt;/strong&gt; and &lt;strong&gt;exploitation&lt;/strong&gt;.
In machine learning, exploration stands for the acquisition of new knowledge, and exploitation refers to an optimized decision based on existing knowledge.
In the case of the multi-armed bandit problem, the gambler needs to decide between trying different arms to get more information about their rewards and playing the arm that has the highest average reward so far.&lt;/p&gt;

&lt;p&gt;The following notations are used throughout the post.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;\(K\) is the total number of arms and \(T\) is the total number of rounds, both are known in advance. Arms are denoted by \(a \in [K]\), rounds by \(t \in [T]\).
&lt;small&gt;
(The bracket notation \([n]\) denotes the first \(n\) positive integers \([n] := \{1, 2, \ldots, n\}\).)
&lt;/small&gt;&lt;/li&gt;
&lt;li&gt;The reward for arm \(a\) is i.i.d. from \(\mathcal{D}_a\), which is a distribution supported on \([0,1]\). The expected reward of arm \(a\) is denoted by \(\mu(a) := \int_0^1 x \, \mathrm{d}\mathcal{D}_a(x)\).&lt;/li&gt;
&lt;li&gt;The best expected reward is denoted by \(\mu^* := \max_{a \in [K]} \mu(a)\), and the best arm is \(a^* = \operatorname{argmax}_{a \in [K]} \mu(a)\).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The (cumulative) &lt;strong&gt;regret&lt;/strong&gt; in round \(t\) is defined as
$$ R(t) =  \mu^* t  - \sum_{s=1}^t \mu(a_s), $$
where \(a_s\) is the chosen arm in round \(s\).
The regret is the difference between the sum of rewards associated with the optimal arm and the sum of expected rewards by an algorithm.
The goal of the algorithm is to minimize the regret.
Note that \(a_s\) is a random quantity, since it may depend on the randomness in rewards and/or the algorithm.
Therefore the regret \(R(t)\) is also random and we are interested in the expected regret \(\mathbb{E}[R(t)]\) or \(\mathbb{E}[R(T)]\).&lt;/p&gt;

&lt;p&gt;It may be a good time now to review the &lt;a href=&#34;https://en.wikipedia.org/wiki/Hoeffding%27s_inequality&#34;&gt;Hoeffding&amp;rsquo;s inequality&lt;/a&gt;, an important concentration inequality widely used in machine learning theory.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Hoeffding&amp;rsquo;s inequality&lt;/strong&gt;&lt;br /&gt;
Let \(X_1, \ldots, X_n\) be independent random variables and let \(\bar{X}=\frac{1}{n}\sum_{i=1}^n X_i\). Assume \(0 \leq X_i \leq 1\) almost surely. Then, for any \(t&amp;gt;0\),
$$\mathbb{P}(|\bar{X} - \mathbb{E}[\bar{X}]| &amp;gt; t) \leq 2 \exp (-2nt^2).$$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;2-explore-first-algorithm&#34;&gt;2. Explore-first algorithm&lt;/h2&gt;

&lt;p&gt;A simple idea is to explore arms uniformly and pick an empirically best arm for exploitation.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Explore-first algorithm&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Exploration phase:     Try each arm \(N\) times. Let \(\bar\mu(a)\) be the average reward for arm \(a\);&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Exploitation phase: Select arm \(\hat{a}\) with the highest average reward \(\hat{a} = \operatorname{argmax}_{a \in [K]} \bar\mu(a)\). Play arm \(\hat{a}\) in all remaining rounds.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;The parameter \(N\) is fixed in advance; it will be chosen later as a function of \(T\) and \(K\).&lt;/p&gt;

&lt;h3 id=&#34;2-1-regret-bound&#34;&gt;2.1 Regret bound&lt;/h3&gt;

&lt;p&gt;Our goal is to give an upper bound of the expected regret \(\mathbb{E}[R(T)]\) as a function of \(K\) and \(T\):
$$
\mathbb{E}[R(T)]=O \big(T^{2 / 3} (K \log T)^{1 / 3} \big).
$$&lt;/p&gt;

&lt;p&gt;To facilitate our analysis, we define the &lt;strong&gt;clean event&lt;/strong&gt; \(C\) to be the event that \(\bar\mu(a)\) is close to \(\mu(a)\) for all arms:
$$
C = \{ |\bar\mu(a) - \mu(a)| \leq r, \forall a \in [k] \},
$$
where \(r\) is called the &lt;strong&gt;confidence radius&lt;/strong&gt;.
The &lt;strong&gt;bad event&lt;/strong&gt; \(\bar{C}\) is the complement of the clean event.
By the &lt;a href=&#34;https://en.wikipedia.org/wiki/Law_of_total_expectation&#34;&gt;law of total expectation&lt;/a&gt;,
$$
\mathbb{E}[R(T)] =
\mathbb{E}[R(T) | C]
\mathbb{P}[C]
+
\mathbb{E}[R(T) | \bar{C}]
\mathbb{P}[\bar{C}].
$$&lt;/p&gt;

&lt;p&gt;First of all, we want to make sure \(\mathbb{P}[\bar{C}]\) is small.
In other words, the average reward \(\bar\mu(a)\) should be a good estimate of the true expected reward \(\mu(a)\).
By Hoeffding&amp;rsquo;s inequality, the deviation of the average reward from the true expected reward can be quantified as follows:&lt;/p&gt;

&lt;p&gt;$$
\mathbb{P}( |\bar\mu(a) - \mu(a)| &amp;gt; r) \leq 2 \exp (-2Nr^2), \quad \forall a \in [k].
$$&lt;/p&gt;

&lt;p&gt;We want to bound this probability by a sufficiently small number, say \(2/T^4\). This can be achieved by setting the confidence radius \(r = \sqrt{\frac{2 \log T}{N}}\):
$$
\mathbb{P}( |\bar\mu(a) - \mu(a)| &amp;gt; r) \leq \frac{2}{T^4}, \quad \forall a \in [k].
$$
Note that the choice of \(T^4\) is somewhat arbitrary; the exponent only affects the multiplicative constant of \(r\).&lt;/p&gt;

&lt;p&gt;Using the &lt;a href=&#34;https://en.wikipedia.org/wiki/Boole%27s_inequality&#34;&gt;union bound&lt;/a&gt;, we can find an upper bound of the probability of the bad event.
$$
\begin{align}
\mathbb{P}(\bar{C})
&amp;amp;=
\mathbb{P} \big(\{ \exists a \in [K] \ \text{s.t.}\ |\bar\mu(a) - \mu(a)| &amp;gt; r \} \big)
\newline
&amp;amp;=
\mathbb{P} \big(\bigcup_{a \in [K]}\{|\bar\mu(a) - \mu(a)| &amp;gt; r \} \big)
\newline
&amp;amp;\leq \sum_{a \in [K]} \mathbb{P} (|\bar\mu(a) - \mu(a)| &amp;gt; r )
\newline
&amp;amp;\leq
\frac{2K}{T^4}
\newline
&amp;amp;\leq
\frac{2}{T^3}.
\end{align}
$$
The last inequality is because each arm is explored at least once, &lt;em&gt;i.e.&lt;/em&gt;, \(T \geq K\).&lt;/p&gt;

&lt;p&gt;Next, we focus on \(\mathbb{E}[R(T) | C]\).
By definition, \(\bar\mu(\hat{a}) \geq \bar\mu(a^*)\).
Given the clean event happens,
an upper bound of \(\mu(a^*) - \mu(\hat{a}) \) can be obtained:
$$
\begin{align}
\mu(a^*) - \mu(\hat{a})
&amp;amp;\leq
\mu(a^*) - \mu(\hat{a}) + \bar\mu(\hat{a}) - \bar\mu(a^*)
\newline
&amp;amp;=
\big(\mu(a^*) - \bar\mu(a^*)\big) + \big(\bar\mu(\hat{a}) - \mu(\hat{a}) \big)
\newline
&amp;amp;\leq 2r.
\end{align}
$$
Intuitively, it indicates that conditioning on the clean event, the chosen arm \(\hat{a}\) cannot be much worse than \(a^*\).&lt;/p&gt;

&lt;p&gt;There are \(NK\) rounds in the exploration phase and each round has at most regret of 1; there are \(T - NK\) rounds in the exploitation phase and the regret incurred in each round is bounded by \(2r\).
As a result, the regret in round \(T\) can be bounded by
$$
\begin{align}
\mathbb{E}[R(T) | C]
&amp;amp;\leq NK + (T - NK) 2r
\newline
&amp;amp;\leq NK + 2Tr
\newline
&amp;amp;= NK + 2T \sqrt{\frac{2 \log T}{N}}.
\end{align}
$$
Since we can choose the number of rounds in the exploration phase,
the right-hand side can be minimized by setting
\( N = (T/K)^{2 / 3} (2\log T)^{1 / 3} \).
Therefore,
$$
\mathbb{E}[R(T) | C]
\leq
T^{2 / 3} (2K\log T)^{1 / 3}.
$$&lt;/p&gt;

&lt;p&gt;So far, we have&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;\(\mathbb{E}[R(T) | C]
\leq
T^{2 / 3} (2K \log T)^{1 / 3}
\);&lt;/li&gt;
&lt;li&gt;\( \mathbb{P}[C] \leq 1 \);&lt;/li&gt;
&lt;li&gt;\( \mathbb{E}[R(T) | \bar{C}] \leq T \), since there are in total \(T\) rounds, each round incurs at most regret of 1;&lt;/li&gt;
&lt;li&gt;\(\mathbb{P}[\bar{C}] \leq 2 / T^4 \).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Putting everything together,
$$
\begin{align}
\mathbb{E}[R(T)] &amp;amp;=
\mathbb{E}[R(T) | C]
\mathbb{P}[C]
+
\mathbb{E}[R(T) | \bar{C}]
\mathbb{P}[\bar{C}]
\newline
&amp;amp;\leq
T^{2 / 3} (2K\log T)^{1 / 3}
+
T \cdot \frac{2}{T^3}
\newline
&amp;amp;= O \big(T^{2 / 3} (K \log T)^{1 / 3} \big).
\end{align}
$$&lt;/p&gt;

&lt;h2 id=&#34;3-upper-confidence-bound-algorithm&#34;&gt;3. Upper confidence bound algorithm&lt;/h2&gt;

&lt;p&gt;The problem with the explore-first algorithm is that each arm is explored for the same number of rounds, which causes inefficiency.
In other words, the exploration schedule should depend on the history of the observed rewards.
Instead of using the same confidence radius for any arm in any round, we denote the confidence radius for arm \(a\) at time \(t\) by \(r_t(a)\).
Let \(n_t(a)\) be the number of times arm \(a\) is selected in rounds \(1, 2, \ldots, t\) and \(\bar\mu_t(a)\)  be the average reward of arm \(a\) up to time \(t\).
The &lt;strong&gt;upper confidence bound&lt;/strong&gt; is defined as
$$
\mathrm{UCB}_t(a) = \bar\mu_t(a) + r_t(a),
$$
where \( r_t(a) = \sqrt{\frac{2 \log T}{n_t(a)}} \).&lt;/p&gt;

&lt;p&gt;The UCB1 algorithm chooses the best arm based on an optimistic estimate. The algorithm is as follows.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;UCB1 algorithm&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Try each arm once;&lt;/li&gt;
&lt;li&gt;In round \(t\), pick \( a_t = \operatorname{argmax}_{a \in [K]} \mathrm{UCB}_t(a)\).&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;Unlike the explore-first algorithm, there is no clear exploration/exploitation phase. However, the definition of the upper confidence bound manifests the exloration-exploitation tradeoff: \(\bar\mu_t(a)\) encourages the exploitation of high reward arms, while \(r_t(a)\) courages the exploration of less played arms.&lt;/p&gt;

&lt;h3 id=&#34;3-1-regret-bound&#34;&gt;3.1 Regret bound&lt;/h3&gt;

&lt;p&gt;The regret bound of the UCB1 algorithm is
$$
\mathbb{E}[R(t)] = O \big(\sqrt{Kt \log T} \big),
\quad
\forall t \in [T].
$$
The idea of the analysis is the same as before: define a clean event \(C\), obtain upper bounds of \(\mathbb{P}[\bar{C}]\) and \(\mathbb{E}[R(t)|C]\), and finally bound \(\mathbb{E}[R(t)]\).&lt;/p&gt;

&lt;p&gt;Since the confidence radius now depends on \(t\) as well, we need a more refined definition of the &lt;strong&gt;clean event&lt;/strong&gt;:
$$
C = \{|\bar\mu_t(a) - \mu(a)| \leq r_t(a), \forall a \in [k], \forall t \in [T] \}.
$$
Applying Hoeffding&amp;rsquo;s inequality and the union bound (and ignoring some technicalities),
$$
\mathbb{P}[\bar{C}] \leq \frac{2KT}{T^4} \leq \frac{2}{T^2}.
$$&lt;/p&gt;

&lt;p&gt;Now we focus on \(\mathbb{E}[R(t)|C]\) and assume the clean event holds.
By definition, \( \mathrm{UCB}_t(a_t) \geq \mathrm{UCB}_t(a^*) \) for any round \(t \in [T]\).
As a result,&lt;/p&gt;

&lt;p&gt;$$
\begin{align}
\mu(a^*) - \mu(a_t)
&amp;amp;\leq
\mu(a^*) - \mu(a_t) + \mathrm{UCB}_t(a_t) - \mathrm{UCB}_t(a^*)
\newline
&amp;amp;= \big(\mu(a^*) - \mathrm{UCB}_t(a^*)\big) + \big(\mathrm{UCB}_t(a_t) - \mu(a_t) \big),
\end{align}
$$
where
$$
\mu(a^*) - \mathrm{UCB}_t(a^*)
=\mu(a^*) - \bar\mu_t(a^*) - r_t(a^*)
\leq 0,
$$
and
$$
\mathrm{UCB}_t(a_t) - \mu(a_t)
=\bar\mu_t(a_t) - \mu(a_t) + r_t(a_t)
\leq 2 r_t(a_t).
$$
Therefore,
$$
\mu(a^*) - \mu(a_t)
\leq
2 r_t(a_t)
= 2 \sqrt{\frac{2 \log T}{n_t(a_t)}}.
$$&lt;/p&gt;

&lt;p&gt;For each arm \(a\) and a given time \(t \in [T]\), consider the last round \(t_0 \leq t\) when this arm is chosen.
Since arm \(a\) is never played between round \(t_0\) and round \(t\), we have \(n_{t_0}(a) = n_t(a)\).
Applying the above inequality to arm \(a\) and round \(t_0\),
$$
\mu(a^*) - \mu(a) \leq 2 \sqrt{\frac{2 \log T}{n_t(a)}},
\quad
\forall t \in [T].
$$
Intuitively it means that, under the clean event, if an arm is selected many times, it cannot be much worse than the best arm; or equivalently, if an arm is much worse than the best arm, it won&amp;rsquo;t be selected many times.&lt;/p&gt;

&lt;p&gt;The regret in round \(t\) is thus bounded by
$$
R(t) = \sum_{a \in [K]}
n_t(a) \big(\mu(a^*) - \mu(a)\big)
\leq
2 \sqrt{2 \log T}
\sum_{a \in [K]}
\sqrt{n_t(a)}.
$$
Since the square root function is concave, by &lt;a href=&#34;https://en.wikipedia.org/wiki/Jensen%27s_inequality&#34;&gt;Jensen&amp;rsquo;s inequality&lt;/a&gt;,
$$
\sum_{a \in [K]}
\sqrt{n_t(a)}
= K \sum_{a \in [K]}
\frac{1}{K} \sqrt{n_t(a)}
\leq
K
\sqrt{\frac{1}{K}\sum_{a \in [K]} n_t(a)}
= \sqrt{Kt}.
$$
Therefore,
$$
\mathbb{E}[R(t)|C] \leq 2 \sqrt{2 Kt \log T}.
$$&lt;/p&gt;

&lt;p&gt;Finally, much like what we did for the explore-first algorithm, the expected regret in round \(t\) can be bounded by
$$
\begin{align}
\mathbb{E}[R(t)] &amp;amp;=
\mathbb{E}[R(t) | C]
\mathbb{P}[C]
+
\mathbb{E}[R(t) | \bar{C}]
\mathbb{P}[\bar{C}]
\newline
&amp;amp;\leq
2 \sqrt{2 Kt \log T}
+
t \cdot \frac{2}{T^2}
\newline
&amp;amp;= O \big(\sqrt{Kt \log T} \big),
\quad
\forall t \in [T].
\end{align}
$$&lt;/p&gt;

&lt;h3 id=&#34;3-2-an-instance-dependent-regret-bound&#34;&gt;3.2 An instance-dependent regret bound&lt;/h3&gt;

&lt;p&gt;We can also obtain another regret bound using the inequality
$$
\mu(a^*) - \mu(a) \leq 2 \sqrt{\frac{2 \log T}{n_T(a)}}.
$$
Rearrange the terms,
$$
n_T(a) \leq \frac{8 \log T}{(\mu(a^*) - \mu(a))^2},
\quad
\text{if }
\mu(a) &amp;lt; \mu(a^*).
$$
The regret in round \(T\) is bounded by
$$
R(T) = \sum_{a \in [K]} n_T(a) \big(\mu(a^*) - \mu(a)\big)
\leq
8 \log T
\sum_{\{a \in [K]: \mu(a) &amp;lt; \mu(a^*)\}}
\frac{1}{\mu(a^*) - \mu(a)}.
$$
Therefore,
$$
\mathbb{E}[R(T)]
\leq
O(\log T)
\sum_{\{a \in [K]: \mu(a) &amp;lt; \mu(a^*)\}}
\frac{1}{\mu(a^*) - \mu(a)}.
$$&lt;/p&gt;

&lt;p&gt;This regret bound is logarithmic in \(T\), with a constant that can be arbitrarily large depending on a problem instance.
This type of regret bound is called &lt;strong&gt;instance-dependent&lt;/strong&gt;. The existence of a logarithmic regret bound is a benefit of the UCB1 algorithm compared to the explore-first algorithm, whose regret bound is polynomial in \(T\).&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;p&gt;Slivkins, A. (2017). Introduction to Multi-Armed Bandits. &lt;a href=&#34;http://slivkins.com/work/MAB-book.pdf&#34;&gt;http://slivkins.com/work/MAB-book.pdf&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Few LaTeX Tips</title>
      <link>https://bochang.me/blog/posts/latex/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://bochang.me/blog/posts/latex/</guid>
      <description>

&lt;p&gt;LaTeX is a high-quality typesetting system and the de facto standard for publication of scientific documents. However, I never got a chance to formally learn how to use it. Most of my LaTeX knowledge comes from learning by doing. As I&amp;rsquo;m working on my Ph.D. thesis, I would like to share a few LaTeX tips that I wish I had known earlier. I got most of them from working with my advisors, internship hosts, and collaborators. There is still a lot for me to learn about LaTeX. Any comments and suggestions are welcome!&lt;/p&gt;

&lt;h2 id=&#34;1-non-breaking-spaces&#34;&gt;1. Non-breaking spaces&lt;/h2&gt;

&lt;p&gt;In digital typesetting, a non-breaking space is a space character that prevents an automatic line break at its position. It is like invisible glue between two words. There are various situations where a non-breaking space is used. For example, if the phrase &amp;ldquo;100 km&amp;rdquo; does not fit at the end of a line, the word processor may insert a line break between &amp;ldquo;100&amp;rdquo; and &amp;ldquo;km&amp;rdquo;, which is not desirable.&lt;/p&gt;

&lt;p&gt;LaTeX uses the &lt;code&gt;~&lt;/code&gt; symbol as a non-breaking space. It is usually inserted before any numeric or alphabetic reference, for example, &lt;code&gt;Figure~\ref{fig:foo}&lt;/code&gt; and &lt;code&gt;Section~\ref{sec:bar}&lt;/code&gt;. Compare the following examples:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Without a non-breaking space: &lt;code&gt;Table 3&lt;/code&gt;
&lt;img src=&#34;nonbreaking-1.png&#34; alt=&#34;without a non-breaking space&#34; /&gt;&lt;/li&gt;
&lt;li&gt;With a non-breaking space: &lt;code&gt;Table~3&lt;/code&gt;
&lt;img src=&#34;nonbreaking-2.png&#34; alt=&#34;with a non-breaking space&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;2-citations-using-citet-and-citep&#34;&gt;2. Citations using &lt;code&gt;\citet&lt;/code&gt; and &lt;code&gt;\citep&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;The &lt;code&gt;natbib&lt;/code&gt; package is commonly used for handling references in LaTeX. It is included in the style files by default for many conferences including ICML, NIPS, ICLR, etc. See &lt;a href=&#34;https://gking.harvard.edu/files/natnotes2.pdf&#34; title=&#34;Reference sheet for natbib usage&#34;&gt;here&lt;/a&gt; for a reference sheet for &lt;code&gt;natbib&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The two basic citation commands in &lt;code&gt;natbib&lt;/code&gt; are&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;\citet&lt;/code&gt; for &lt;strong&gt;textual&lt;/strong&gt; citations,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;\citep&lt;/code&gt; for &lt;strong&gt;parenthetical&lt;/strong&gt; citations.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The difference is that &lt;code&gt;\citet{jon90}&lt;/code&gt; prints &lt;em&gt;Jones et al. (1990)&lt;/em&gt;, while &lt;code&gt;\citep{jon90}&lt;/code&gt; prints &lt;em&gt;(Jones et al., 1990)&lt;/em&gt;. The choice depends on whether the authors are to be read as part of the sentence. According to the formatting instructions for ICLR 2019:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;When the authors or the publication are included in the sentence, the citation should not be in parenthesis (as in “See Hinton et al. (2006) for more information.”). Otherwise, the citation should be in parenthesis (as in “Deep learning shows promise to make progress towards AI (Bengio &amp;amp; LeCun, 2007).”).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The command &lt;code&gt;\cite&lt;/code&gt; should be avoided because its behavior depends on the citation format and might cause inconsistency. According to the &lt;code&gt;natbib&lt;/code&gt; documentation:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The standard LaTeX command &lt;code&gt;\cite&lt;/code&gt; should be avoided, because it behaves like &lt;code&gt;\citet&lt;/code&gt; for author-year citations, but like &lt;code&gt;\citep&lt;/code&gt; for numerical ones.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;3-mathematical-symbols&#34;&gt;3. Mathematical symbols&lt;/h2&gt;

&lt;p&gt;When writing mathematical formulas, people follow certain conventions of notations. In fact, there is an ISO standard &lt;a href=&#34;https://people.engr.ncsu.edu/jwilson/files/mathsigns.pdf&#34;&gt;ISO 80000-2&lt;/a&gt; that defines mathematical signs and symbols. I found an article titled &lt;a href=&#34;https://tug.org/TUGboat/tb18-1/tb54becc.pdf&#34;&gt;Typesetting mathematics for science and technology according to ISO 31/XI&lt;/a&gt; by Claudio Beccari. &lt;small&gt;(ISO 31/XI is the precursor of ISO 80000-2.)&lt;/small&gt; The recommendations below are excerpts of the article. The &amp;ldquo;roman type&amp;rdquo; refers to upright letters and the &amp;ldquo;italic type&amp;rdquo; refers to sloping letters.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;a) Variables and functions are represented by one italic letter with modifiers such as subscripts, superscripts, primes, etc.&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;LaTeX&lt;/th&gt;
&lt;th&gt;Display&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;L(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(L(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;L&#39;(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(L&amp;rsquo;(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;L_{\mathrm{adversarial}}(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(L_{\mathrm{adversarial}}(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Incorrect&lt;/td&gt;
&lt;td&gt;&lt;code&gt;LOSS(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(LOSS(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Incorrect&lt;/td&gt;
&lt;td&gt;&lt;code&gt;Loss(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(Loss(x)\)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;b) Mathematical operators indicated with letters must be set in roman type.&lt;/strong&gt;
This includes the predefined operators &lt;code&gt;\exp&lt;/code&gt;, &lt;code&gt;\log&lt;/code&gt;, &lt;code&gt;\sin&lt;/code&gt;, &lt;code&gt;\tanh&lt;/code&gt;, &lt;code&gt;\det&lt;/code&gt;, &lt;code&gt;\min&lt;/code&gt;, &lt;code&gt;\inf&lt;/code&gt;, as well as user-defined operators.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;LaTeX&lt;/th&gt;
&lt;th&gt;Display&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;\sin(2x) = 2 \sin(x) \cos(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(\sin(2x) = 2 \sin(x) \cos(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Incorrect&lt;/td&gt;
&lt;td&gt;&lt;code&gt;sin(2x) = 2 sin(x) cos(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(sin(2x) = 2 sin(x) cos(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;\operatorname{softmax}(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(\operatorname{softmax}(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Incorrect&lt;/td&gt;
&lt;td&gt;&lt;code&gt;softmax(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(softmax(x)\)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;c) A particular operator, the operator of differentiation, should be set in roman type.&lt;/strong&gt;
This one is somewhat controversial. In some fields, italic type seems more common. I personally prefer roman type.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;LaTeX&lt;/th&gt;
&lt;th&gt;Display&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;\int x \mathrm{d} x&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(\int x \mathrm{d} x\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Incorrect&lt;/td&gt;
&lt;td&gt;&lt;code&gt;\int x dx&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(\int x dx\)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;d) Sub and superscripts that do not represent mathematical variables should be set in roman type.&lt;/strong&gt;
The first row is correct because \(n\) represents a variable here.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;LaTeX&lt;/th&gt;
&lt;th&gt;Display&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;S_n = \sum_{i=1}^n X_i&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\( S_n = \sum_{i=1}^n X_i \)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;L_{\mathrm{adversarial}}(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(L_{\mathrm{adversarial}}(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Incorrect&lt;/td&gt;
&lt;td&gt;&lt;code&gt;L_{adversarial}(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(L_{adversarial}(x)\)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;4-avoid-vspace&#34;&gt;4. Avoid &lt;code&gt;\vspace&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;Most conferences have strict page limits. More often than not, eight pages are not enough to fully present a brilliant idea. If only Fermat got more space in the margin!&lt;/p&gt;

&lt;p&gt;A common trick is to use &lt;code&gt;\vspace&lt;/code&gt;. It can reduce the length of a vertical space before or after a section, figure or table. However, this essentially alters the style template. Many formatting instructions explicitly forbid the use of &lt;code&gt;\vspace&lt;/code&gt;. It might even result in the rejection of the paper. From the formatting instructions for AAAI 2019:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;if your paper is obviously &amp;ldquo;squeezed&amp;rdquo; it is not going to be accepted.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Reducing the vertical spaces also makes the paper less readable for the reviewers, so it is obviously not advisable.
Many conferences support the submission of supplementary material. If your paper is too long, consider reorganizing it and moving some sections to the supplementary material.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>