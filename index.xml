<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bo&#39;s Blog</title>
    <link>https://bochang.me/blog/</link>
    <description>Recent content on Bo&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Aug 2019 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://bochang.me/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Importance Weighted Autoencoders and Jackknife Methods</title>
      <link>https://bochang.me/blog/posts/iwae/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bochang.me/blog/posts/iwae/</guid>
      <description>

&lt;p&gt;This blog post is a summary of two papers: Burda et al. (2015) and Nowozin (2018).
We first give a quick overview of variational inference and variational autoencoders (VAE), which approximate the posterior distribution by a simpler distribution and maximize the evidence lower bound (ELBO).
Blei et al. (2017) and Zhang et al. (2018) are among some excellent survey papers on variational inference.
Next, the importance weighted autoencoder (IWAE) is introduced, and its properties are presented.
Finally, we describe the jackknife variational inference (JVI) as a way to reduce the bias of IWAE estimators.&lt;/p&gt;

&lt;h2 id=&#34;variational-autoencoders&#34;&gt;Variational autoencoders&lt;/h2&gt;

&lt;p&gt;Consider a Bayesian model involving the (set of) latent variable $z$ and  observation $x$, where the joint density can be decomposed into
$$
p(x, z) = p(x | z) p(z),
$$
where $p(x | z)$ is the likelihood and $p(z)$ is the prior distribution of the latent variable $z$.
The posterior distribution $p(z|x)$ is of central interest in Bayesian inference.
However, it is often intractable, and approximate inference is required.&lt;/p&gt;

&lt;p&gt;Variational inference aims to approximate the posterior distribution by a variational distribution and to derive a lower bound of the marginal log-likelihood of data $\log p(x)$.
Variational autoencoder (VAE) is a type of amortized variational inference method.
Here, &amp;ldquo;amortized&amp;rdquo; means that the variational distribution $q(z|x)$ is parametrized by a function of $x$, whose parameters are shared across all observations.&lt;/p&gt;

&lt;p&gt;We first rewrite the marginal log-likelihood by introducing the variational distribution $q(z|x)$:
\begin{align}
\log p(x) &amp;amp;= \log \int p(x|z) p(z) \mathrm{d} z
\newline
&amp;amp;= \log \int \frac{p(x|z) p(z)}{q(z|x)} q(z|x) \mathrm{d} z
\newline
&amp;amp;= \log \mathbb{E}_{q(z|x)} \left[ \frac{p(x|z) p(z)}{q(z|x)} \right].
\label{eq:marginal}
\tag{1}
\end{align}
If we pull the expectation out of the logarithm function, which is concave, &lt;a href=&#34;https://en.wikipedia.org/wiki/Jensen%27s_inequality&#34;&gt;Jensen&amp;rsquo;s inequality&lt;/a&gt; gives the following inequality:
$$
\log p(x) \ge
\mathbb{E}_{q(z|x)}
\log \left[ \frac{p(x|z) p(z)}{q(z|x)} \right].
\label{eq:elbo}
\tag{2}
$$
The right-hand side is called the evidence lower bound (ELBO), denoted by $\mathcal{L}$.
The inference problem then becomes an optimization problem that tries to find a variational distribution $q(z|x)$ that maximizes $\mathcal{L}$.&lt;/p&gt;

&lt;p&gt;There are at least three ways of rewriting the ELBO:
\begin{align}
\mathcal{L} &amp;amp;=
\log p(x) - D_{\mathrm{KL}} ( q(z|x) \parallel p(z|x) )
\newline
&amp;amp;=
\mathbb{E}_{q(z|x)} \log p(x,z) + \mathbb{E}_{q(z|x)} [-\log q(z|x)]
\newline
&amp;amp;=
\mathbb{E}_{q(z|x)} \log p(x|z)
- D_{\mathrm{KL}} ( q(z|x) \parallel p(z) )
\end{align}&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The first equation shows that the difference between the marginal log-likelihood $\log p(x)$ and the ELBO $\mathcal{L}$ is the KL divergence between $q(z|x)$ and $p(z|x)$.
When these two distributions are identical (almost everywhere), the marginal log-likelihood equals the ELBO.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;In the second equation, the first term represents the &amp;ldquo;energy&amp;rdquo; and the second term represents the entropy of $q(z|x)$. The energy term encourages $q(z|x)$ to focus probability mass on where the joint probability $p(x, z)$ is large. The entropy encourages $q(z|x)$ to spread the probability mass to avoid concentrating on one location.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The third equation is a more explicit representation of the standard architecture of a variational autoencoder.
The variational distribution $q(z|x)$ and the likelihood function $p(x|z)$ are represented by an encoder network and a decoder network, respectively.
Furthermore, $q(z|x)$ and $p(z)$ are often assumed to be multivariate independent Gaussian so that their KL divergence is of closed-form.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A simple Monte Carlo estimator of the ELBO $\mathcal{L}$ approximates the expectation in Equation \ref{eq:elbo} by the sample mean.
Let $z_i$, for $i=1, \ldots, k$, be independent samples drawn from $q(z|x)$, then the estimator is
$$
\widehat{\mathcal{L}}_k^{\mathrm{ELBO}} :=
\frac{1}{k} \sum_{i=1}^k \log \left[ \frac{p(x|z_i) p(z_i)}{q(z_i|x)} \right].
$$
It is obvious that the estimator is unbiased, i.e., $\mathbb{E}_{z_i \sim q(z|x)} \widehat{\mathcal{L}}_k^{\mathrm{ELBO}} = \mathcal{L}$.&lt;/p&gt;

&lt;h2 id=&#34;importance-weighted-autoencoders&#34;&gt;Importance weighted autoencoders&lt;/h2&gt;

&lt;p&gt;What we have described so far is first to define the ELBO $\mathcal{L}$ as a lower bound of $\log p(x)$, and then to estimate it by $\widehat{\mathcal{L}}_k^{\mathrm{ELBO}}$.
An alternative approach is to approximate the expectation (inside the logarithm function) in Equation \ref{eq:marginal} by Monte Carlo, which leads to the importance weighted autoencoders (IWAE) estimator:
$$
\widehat{\mathcal{L}}_k^{\mathrm{IWAE}} :=
\log \left[ \frac{1}{k} \sum_{i=1}^k  \frac{p(x|z_i) p(z_i)}{q(z_i|x)} \right].
$$
Note the difference between $\widehat{\mathcal{L}}_k^{\mathrm{ELBO}}$ and $\widehat{\mathcal{L}}_k^{\mathrm{IWAE}}$.&lt;/p&gt;

&lt;p&gt;If we denote $\mathcal{L}_k := \mathbb{E}_{z_i \sim q(z|x)} \widehat{\mathcal{L}}_k^{\mathrm{IWAE}}$, then by Jensen&amp;rsquo;s inequality,
$$
\mathcal{L}_k
\le \log \left[ \mathbb{E}_{z_i \sim q(z|x)} \frac{1}{k} \sum_{i=1}^k  \frac{p(x|z_i) p(z_i)}{q(z_i|x)} \right]
= \log p(x).
$$
In other words, the expectation of $\widehat{\mathcal{L}}_k^{\mathrm{IWAE}}$ is also a lower bound of $\log p(x)$.
When $k=1$, the ELBO and IWAE estimators are equivalent.
It can be shown that $\mathcal{L}_k$ is tighter than $\mathcal{L}$ when $k&amp;gt;1$:
$$
\mathcal{L} = \mathcal{L}_1 \le \mathcal{L}_2 \le \cdots \le \log p(x),
$$
and
$$
\lim_{k \to \infty} \mathcal{L}_k = \log p(x).
$$
Unsurprisingly, $\widehat{\mathcal{L}}_k^{\mathrm{IWAE}}$ also converges in probability to $\log p(x)$ as $k\to \infty$.
A more detailed asymptotic analysis shows that
$$
\mathcal{L}_k
= \log p(x) - \frac{\mu_2}{2 \mu^2} \frac{1}{k}
+ \left( \frac{\mu_3}{3\mu^2} - \frac{3\mu_2^2}{4\mu^4} \right) \frac{1}{k^2}
+ O(k^{-3}),
$$
where $\mu$ and $\mu_j$ are the expectation and the $j$-th central moment of $p(x|z_i) p(z_i) / q(z_i|x)$ with $z_i \sim q(z|x)$, respectively.&lt;/p&gt;

&lt;p&gt;An interesting perspective on the IWAE is that, $\widehat{\mathcal{L}}_k^{\mathrm{IWAE}}$ can be regarded as an estimator of $\log p(x)$.
As shown above, the estimator is &lt;a href=&#34;https://en.wikipedia.org/wiki/Consistent_estimator&#34;&gt;consistent&lt;/a&gt; but &lt;a href=&#34;https://en.wikipedia.org/wiki/Bias_of_an_estimator&#34;&gt;biased&lt;/a&gt;, and the bias is in the order of $O(k^{-1})$.
The remaining sections try to reduce the bias to a higher/smaller order so that the estimator is closer to the marginal log-likelihood when $k$ is large.&lt;/p&gt;

&lt;h2 id=&#34;jackknife-resampling&#34;&gt;Jackknife resampling&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&#34;https://en.wikipedia.org/wiki/Jackknife_resampling&#34;&gt;jackknife&lt;/a&gt; is a resampling technique that can be used to estimate the bias of an estimator and further to reduce the bias.
Let $\widehat{T}_n$ be a consistent but biased estimator of $T$, evaluated on $n$ samples.
Assume the expectation $\mathbb{E} (\widehat{T}_n)$ can be written as an asymptotic expansion as $n \to \infty$:
$$
\mathbb{E} (\widehat{T}_n) = T + \frac{a_1}{n} + \frac{a_2}{n^2} + O(n^{-3}).
$$
Then the bias of $\widehat{T}_n$ is in the order of $O(n^{-1})$.&lt;/p&gt;

&lt;p&gt;A debiased estimator $\widetilde{T}_{n,1}$ can be defined as follows:
$$
\widetilde{T}_{n,1} := n \widehat{T}_n - (n-1) \widehat{T}_{n-1}.
$$
The idea is that the first order term is canceled by calculating the difference.
\begin{align}
\mathbb{E} (\widetilde{T}_{n,1})
&amp;amp;= n \mathbb{E} (\widehat{T}_n) - (n-1) \mathbb{E} (\widehat{T}_{n-1})
\newline
&amp;amp;= n \left( T + \frac{a_1}{n} + \frac{a_2}{n^2} + O(n^{-3}) \right)
\newline
&amp;amp;\qquad - (n-1) \left( T + \frac{a_1}{n-1} + \frac{a_2}{(n-1)^2} + O(n^{-3}) \right)
\newline
&amp;amp;= T + \frac{a_2}{n} - \frac{a_2}{n-1} + O(n^{-2})
\newline
&amp;amp;= T + O(n^{-2}).
\end{align}
The bias of $\widetilde{T}_{n,1}$ is in the order of $O(n^{-2})$ instead of $O(n^{-1})$.
When $n$ is large, $\widetilde{T}_{n,1}$ has a lower bias than $\widehat{T}_n$.&lt;/p&gt;

&lt;p&gt;The estimator $\widehat{T}_{n-1}$ can be calculated on any $n-1$ samples. In practice, given $n$ samples, it is evaluated on the $n$ &amp;ldquo;leave-one-out&amp;rdquo; subsets of size $n-1$, and the average of the $n$ estimates is used in place of $\widehat{T}_{n-1}$, which reduces the variance of the estimator.&lt;/p&gt;

&lt;p&gt;The above debiasing method can be further generalized to higher orders.
For example, let
$$
\widetilde{T}_{n,2}
:= \frac{n^2}{2} \widehat{T}_n
- (n-1)^2 \widehat{T}_{n-1}
+ \frac{(n-2)^2}{2} \widehat{T}_{n-2},
$$
then
$$
\mathbb{E} ( \widetilde{T}_{n,2} )
= T + O(n^{-3}),
$$
that is, the bias of $\widetilde{T}_{n,2}$ is in the order of $O(n^{-3})$.
More generally, for
$$
\widetilde{T}_{n,m}
:= \sum_{j=0}^m c(n, m, j) \widehat{T}_{n-j},
$$
where
$$
c(n, m, j) = (-1)^j \frac{(n-j)^m}{(m-j)! j!},
$$
the bias is in the order of $O(n^{-(m+1)})$.&lt;/p&gt;

&lt;h2 id=&#34;jackknife-variational-inference&#34;&gt;Jackknife variational inference&lt;/h2&gt;

&lt;p&gt;The application of the jackknife method to the IWAE estimator should be straightforward.
The jackknife variational inference (JVI) estimator is defined as follows:
$$
\widehat{\mathcal{L}}_{k,1}^{\mathrm{JVI}}
:= k \widehat{\mathcal{L}}_k^{\mathrm{IWAE}}
- (k-1) \widehat{\mathcal{L}}_{k-1}^{\mathrm{IWAE}},
$$
and more generally,
$$
\widehat{\mathcal{L}}_{k,m}^{\mathrm{JVI}}
:= \sum_{j=0}^m c(k, m, j) \widehat{\mathcal{L}}_{k-j}^{\mathrm{IWAE}}.
$$
The bias of $\widehat{\mathcal{L}}_{k,m}^{\mathrm{JVI}}$, as an estimator of $\log p(x)$, is thus in the order of $O(k^{-(m+1)})$.&lt;/p&gt;

&lt;p&gt;Again, the IWAE estimator $\widehat{\mathcal{L}}_{k-j}^{\mathrm{IWAE}}$ can be evaluated on a single subset of samples of size $k-j$, or by the average of that on all subsets of size $k-j$.
In the latter case, the computational cost is significant since $\sum_{j=0}^m {k \choose j}$ could be large; the time complexity is bounded by
$$
O \left( k e^m \left( \frac{k}{m} \right)^m \right).
$$
In practice, the algorithm is feasible only for small values of $m$.
Other variations of JVI are also provided by Nowozin (2018), at the cost of higher variance of the estimator.&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Blei, D. M., Kucukelbir, A., &amp;amp; McAuliffe, J. D. (2017). Variational inference: A review for statisticians. Journal of the American Statistical Association, 112(518), 859-877.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Burda, Y., Grosse, R., &amp;amp; Salakhutdinov, R. (2015). Importance weighted autoencoders. International Conference on Learning Representations.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Nowozin, S. (2018). Debiasing evidence approximations: On importance-weighted autoencoders and jackknife variational inference. International Conference on Learning Representations.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Zhang, C., Butepage, J., Kjellstrom, H., &amp;amp; Mandt, S. (2018). Advances in variational inference. IEEE transactions on pattern analysis and machine intelligence.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Copula: A Very Short Introduction</title>
      <link>https://bochang.me/blog/posts/copula/</link>
      <pubDate>Wed, 08 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bochang.me/blog/posts/copula/</guid>
      <description>

&lt;p&gt;You might have seen the following true/false questions in the final exam of your first statistics course.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;If \( (Z_1, Z_2) \) follows a bivariate Gaussian distribution, do \( Z_1 \) and \( Z_2 \) follow univariate Gaussian distributions?&lt;/li&gt;
&lt;li&gt;If \( Z_1 \) and \( Z_2 \) follow univariate Gaussian distributions, does \( (Z_1, Z_2) \) follow a bivariate Gaussian distribution?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The answer to the first question is &lt;em&gt;true&lt;/em&gt; and to the second is &lt;em&gt;false&lt;/em&gt;.
“What could the joint distribution of \( (Z_1, Z_2) \) be, if \( Z_1 \) and \( Z_2 \) are univariate Gaussians?”, you may ask.&lt;/p&gt;

&lt;p&gt;Figure 1 shows the contour plots for different bivariate distributions where \(Z_1\) and \(Z_2\) follow standard Gaussian distributions. All of them are constructed using &lt;strong&gt;copulas&lt;/strong&gt;, which are a flexible tool to model the dependence among random variables.
In this post, I give a short introduction to (bivariate) copulas.
Other references on this topic include an introduction by &lt;a href=&#34;http://www.angelfire.com/falcon/isinotes/mult/cop1.pdf&#34;&gt;Schmidt (2007)&lt;/a&gt; and a monograph by my Ph.D. advisor &lt;a href=&#34;https://www.crcpress.com/Dependence-Modeling-with-Copulas/Joe/p/book/9781466583221&#34;&gt;Joe (2014)&lt;/a&gt;.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&#34;normal_plots.png&#34; alt=&#34;Contour plots of density function.&#34; width=&#34;600&#34;/&gt;
    &lt;figcaption&gt;Figure 1: Contour plots of density functions.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&#34;1-copula-a-first-glance&#34;&gt;1. Copula&amp;ndash;a first glance&lt;/h2&gt;

&lt;p&gt;Consider a continuous random vector \((X_1, X_2)\).
Let \(F_j\) be the marginal cumulative distribution function (CDF) of \(X_j\) for \(j=1,2\), and \(F\) be the joint CDF.
We apply the probability integral transform and define \(U_j := F_j(X_j)\).
Since \(X_j\) is assumed to be continuous, \(U_j \sim \mathcal{U}(0,1) \) follows a uniform distribution.
Then the CDF of \((U_1, U_2)\) is the &lt;strong&gt;copula&lt;/strong&gt; of \((X_1, X_2)\), denoted by \(C\).
$$C(u_1, u_2) = \mathbb{P}(U_1 \leq u_1, U_2 \leq u_2).$$
The joint distribution can be then decomposed into two components: the copula and marginals:
\begin{align}
F(x_1, x_2)
&amp;amp;= \mathbb{P}(X_1 \leq x_1, X_2 \leq x_2)
\newline
&amp;amp;= \mathbb{P}(U_1 \leq F_1(x_1), U_2 \leq F_2(x_2))
\newline
&amp;amp;= C(F_1(x_1), F_2(x_2)).
\end{align}&lt;/p&gt;

&lt;p&gt;The name &amp;ldquo;copula&amp;rdquo; comes from the Latin for &amp;ldquo;link&amp;rdquo;; it links the marginals to the joint distribution.&lt;/p&gt;

&lt;p&gt;We first consider a few simple copulas.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example 1&lt;/strong&gt; (Independence copula). Let \(X_1\) and \(X_2\) be independent random variables. The corresponding copula is
\begin{align}
C(u_1, u_2)
&amp;amp;=
\mathbb{P}(U_1 \leq u_1, U_2 \leq u_2)
\newline
&amp;amp;=
\mathbb{P}(U_1 \leq u_1) \mathbb{P}(U_2 \leq u_2)
\newline
&amp;amp;=
u_1 u_2.
\end{align}
The second equality is due to independence of \(U_1\) and \(U_2\), and the last equality is because \(U_1\) and \(U_2\) follow uniform distributions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example 2&lt;/strong&gt; (Comonotonicity copula). Let \(X_2 = 2X_1\); that is, \(X_1\) and \(X_2\) have a deterministic and positive relationship.
We can derive the relation between the CDFs:
$$F_1(x) = \mathbb{P}(X_1 \leq x) = \mathbb{P}(2 X_1 \leq 2 x) = \mathbb{P}(X_2 \leq 2x) = F_2(2x),$$
which leads to the fact that \(U_1\) is equal to \(U_2\):
$$U_1 = F_1(X_1) = F_2(2 X_1) = F_2(X_2) = U_2.$$
The copula is
\begin{align}
C(u_1, u_2)
&amp;amp;=
\mathbb{P}(U_1 \leq u_1, U_2 \leq u_2)
\newline
&amp;amp;=
\mathbb{P}(U_1 \leq u_1, U_1 \leq u_2)
\newline
&amp;amp;=
\mathbb{P}(U_1 \leq \min \{u_1, u_2\})
\newline
&amp;amp;=
\min \{u_1, u_2\}.
\end{align}
The comonotonicity copula has perfect positive dependence.
Note that \(X_2 = 2X_1\) can be replaced by \(X_2 = T(X_1)\) for any strictly increasing transformation \(T\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example 3&lt;/strong&gt; (Countermonotonicity copula).
Similar to the previous example, we consider the perfect negative dependence.
Let \(X_2 = -2X_1\), then
$$F_1(x) = \mathbb{P}(X_1 \leq x) = \mathbb{P}(-2 X_1 \geq -2x) = \mathbb{P}(X_2 \geq -2x) = 1 - F_2(-2x),$$
and
$$U_1 = F_1(X_1) = 1-F_2(-2X_1) = 1-F_2(X_2) = 1-U_2.$$
The copula is
\begin{align}
C(u_1, u_2)
&amp;amp;=
\mathbb{P}(U_1 \leq u_1, U_2 \leq u_2)
\newline
&amp;amp;=
\mathbb{P}(U_1 \leq u_1, 1-U_1 \leq u_2)
\newline
&amp;amp;=
\mathbb{P}(1 - u_2 \leq U_1 \leq u_1)
\newline
&amp;amp;=
\max \{u_1 + u_2 - 1, 0\}.
\end{align}
The countermonotonicity copula is the copula of \(X_2 = T(X_1)\) for any strictly decreasing transformation \(T\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example 4&lt;/strong&gt; (Bivariate Gaussian copula).
The previous examples are all extreme cases, with either perfect dependence or independence.
We now introduce a copula that is derived from the bivariate Gaussian distribution.
Consider
$$\begin{pmatrix}
X_1 \newline
X_2
\end{pmatrix}  \sim \mathcal{N} \left( \begin{pmatrix}
0 \newline
0
\end{pmatrix} , \begin{pmatrix}
1 &amp;amp; \rho \newline
\rho &amp;amp; 1
\end{pmatrix} \right).$$
The copula is
\begin{align}
C(u_1, u_2)
&amp;amp;=
\mathbb{P}(U_1 \leq u_1, U_2 \leq u_2)
\newline
&amp;amp;=
\mathbb{P}(X_1 \leq \Phi^{-1}(u_1), X_2 \leq \Phi^{-1}(u_2))
\newline
&amp;amp;=
\Phi_2(\Phi^{-1}(u_1), \Phi^{-1}(u_2); \rho),
\end{align}
where \(\Phi\) is the CDF of a standard normal distribution and \(\Phi_2(\cdot; \rho)\) is the joint CDF of \((X_1, X_2)\).
Also different from the previous example, this is the first parametric copula family we have introduced. The Gaussian copula has a parameter \(\rho\) controlling the strength of dependence.&lt;/p&gt;

&lt;h2 id=&#34;2-common-parametric-copula-families&#34;&gt;2. Common parametric copula families&lt;/h2&gt;

&lt;p&gt;We now give a more general definition of bivariate copulas.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Definition 1.&lt;/strong&gt;
A bivariate copula \(C: [0,1]^2 \to [0,1]\) is a function which is a bivariate cumulative distribution function with uniform marginals.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The copulas we have introduced so far are all derived from bivariate distributions. In other words, it goes from the joint distribution \(F\) on the left-hand side of the following equation to the copula \(C\) and marginals \(F_j\) on the right-hand side.
$$F(x_1, x_2) = C(F_1(x_1), F_2(x_2)).$$&lt;/p&gt;

&lt;p&gt;Given the general definition of the copula, some copula families \(C\) can further be defined explicitly.
This allows us to go from the right-hand side to the left-hand side; that is, linking two marginals using a copula to get a joint distribution.&lt;/p&gt;

&lt;p&gt;Below are shown some commonly used parametric bivariate copula families, where \(\rho, \nu\) and \(\delta\) are the parameters.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Copula family&lt;/th&gt;
&lt;th&gt;Copula CDF&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Gaussian&lt;/td&gt;
&lt;td&gt;\(\Phi_2 \left( \Phi^{-1}(u_1), \Phi^{-1}(u_2); \rho \right)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;t&lt;/td&gt;
&lt;td&gt;\( T_{2, \nu} \left(T_{1, \nu}^{-1}(u_1), T_{1, \nu}^{-1}(u_2); \rho \right) \)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Frank&lt;/td&gt;
&lt;td&gt;\( -\delta^{-1} \log \left( \frac{1 - e^{-\delta} - (1 - e^{-\delta u_1}) (1 - e^{-\delta u_2})} {1-e^{-\delta}} \right) \)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;MTCJ&lt;/td&gt;
&lt;td&gt;\( (u_1^{-\delta} + u_2^{-\delta} - 1)^{-1/\delta} \)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Joe&lt;/td&gt;
&lt;td&gt;\( 1 - \left( (1-u_1)^{\delta} + (1-u_2)^{\delta} - (1-u_1)^{\delta} (1-u_2)^{\delta} \right)^{1/\delta} \)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Gumbel&lt;/td&gt;
&lt;td&gt;\( \exp \left( -\left( (-\log u_1)^{\delta} + (-\log u_2)^{\delta} \right)^{1/\delta} \right) \)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Figure 1 shows the constructed bivariate joint distributions using the copula families above and univariate standard normal distributions (i.e., \(F_1 = F_2 = \Phi\)).&lt;/p&gt;

&lt;h2 id=&#34;3-fréchet-hoeffding-bounds&#34;&gt;3. Fréchet&amp;ndash;Hoeffding bounds&lt;/h2&gt;

&lt;p&gt;As hinted before, the comonotonicity and countermonotonicity copulas are two extreme cases: perfect positive dependence and perfect negative dependence.
This is formally stated by the following theorem.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem 1&lt;/strong&gt; (Fréchet&amp;ndash;Hoeffding bounds).&lt;br /&gt;
For any copula \( C:[0,1]^2 \to [0,1] \) and any \( (u_1, u_2) \in [0,1]^2 \), the following bounds hold:
$$\max \{ u_1+u_2-1, 0 \} \leq C(u_1, u_2) \leq \min \{ u_1, u_2 \}.$$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Figure 2 shows the upper and lower bounds in green and blue respectively.
By the theorem, every copula lies between the two surfaces.&lt;/p&gt;

&lt;p&gt;&lt;div id=&#34;fh_bounds&#34;&gt;&lt;/div&gt;
&lt;figcaption&gt;Figure 2: Fréchet&amp;ndash;Hoeffding bounds. The figure is interactive. &lt;/figcaption&gt;&lt;/p&gt;

&lt;h2 id=&#34;4-reflected-copula&#34;&gt;4. Reflected copula&lt;/h2&gt;

&lt;p&gt;Given \( (U_1, U_2) \sim C \), the reflected copula \(\widehat{C}\) is defined as the copula of \( (1-U_1, 1-U_2) \). That is,
\begin{align}
\widehat{C}(u_1, u_2) &amp;amp;=
\mathbb{P}(1 - U_1 \leq u_1, 1 - U_2 \leq u_2)
\newline
&amp;amp;=
\mathbb{P}(U_1 \geq 1 - u_1, U_2 \geq 1 - u_2).
\end{align}&lt;/p&gt;

&lt;p&gt;The reflected copula \(\widehat{C}\) is handy when studying the upper and lower tail properties of a copula, as we will see later.
To facilitate the analysis, we calculate the following probability (survival function):
\begin{align}
\mathbb{P}(U_1 &amp;gt; v_1, U_2 &amp;gt; v_2)
&amp;amp;=
1 - \mathbb{P}(U_1 \leq v_1 \mbox{ or } U_2 \leq v_2)
\newline
&amp;amp;=
1 - \mathbb{P}(U_1 \leq v_1) - \mathbb{P}(U_2 \leq v_2) + \mathbb{P}(U_1 \leq v_1, U_2 \leq v_2)
\newline
&amp;amp;=
1 -  v_1 - v_2 + C(v_1, v_2).
\end{align}
The second equality is due to the &lt;a href=&#34;https://en.wikipedia.org/wiki/Inclusion%E2%80%93exclusion_principle&#34;&gt;inclusion–exclusion principle&lt;/a&gt;.
Finally, we have
$$\widehat{C}(u_1, u_2) = u_1 + u_2 - 1 + C(1-u_1, 1-u_2).$$&lt;/p&gt;

&lt;h2 id=&#34;5-rank-correlations&#34;&gt;5. Rank correlations&lt;/h2&gt;

&lt;p&gt;Correlation coefficients are useful in summarizing the dependence structure between two variables using a single number.
&lt;a href=&#34;https://en.wikipedia.org/wiki/Pearson_correlation_coefficient&#34;&gt;Pearson&amp;rsquo;s correlation&lt;/a&gt; is probably the most commonly used one.
However, it is known that Pearson&amp;rsquo;s correlation between \(X\) and \(X^2\) is zero for \(X \sim \mathcal{N} (0, 1)\).
This is often used as an example to illustrate that Pearson&amp;rsquo;s correlation only measures linear correlation; it is not invariant under increasing transformations.&lt;/p&gt;

&lt;p&gt;In nonparametric statistics, rank correlations, such as &lt;a href=&#34;https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient&#34;&gt;Spearman&amp;rsquo;s rho&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient&#34;&gt;Kendall&amp;rsquo;s tau&lt;/a&gt;, are defined by the ranks of the data rather than the data itself.
As a result, they are invariant under increasing transformations.
Since copulas are also independent of marginals, there should be a natural connection between copulas and rank correlations.
In fact, both Spearman&amp;rsquo;s rho and Kendall&amp;rsquo;s tau can be defined directly as functionals of a copula.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Spearman&amp;rsquo;s rho:
$$
\rho_S( C ) = \iint_{[0,1]^2}
uv \, \mathrm{d} C(u, v)
-3.
$$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kendall&amp;rsquo;s tau:
$$
\rho_\tau( C ) = \iint_{[0,1]^2}
C(u, v) \, \mathrm{d} C(u, v).
$$&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The integrals are &lt;a href=&#34;https://en.wikipedia.org/wiki/Riemann%E2%80%93Stieltjes_integral&#34;&gt;Riemann&amp;ndash;Stieltjes integrals&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The parameters of bivariate copulas in Figure 1 are chosen such that their Kendall&amp;rsquo;s tau all equals 0.5.&lt;/p&gt;

&lt;h2 id=&#34;6-tail-dependence&#34;&gt;6. Tail dependence&lt;/h2&gt;

&lt;p&gt;Apart from correlation coefficients, the coefficient of tail dependence is also an essential measure of dependence. It characterizes the dependence of a bivariate distribution in the extremes, which is important in many financial applications.&lt;/p&gt;

&lt;p&gt;Consider the following bivariate Gaussian distribution
$$\begin{pmatrix}
X_1 \newline
X_2
\end{pmatrix}  \sim \mathcal{N} \left( \begin{pmatrix}
0 \newline
0
\end{pmatrix} , \begin{pmatrix}
1 &amp;amp; 0.5 \newline
0.5 &amp;amp; 1
\end{pmatrix} \right).$$
We are interested in the conditional probability \(\mathbb{P}(X_2&amp;gt;t | X_1&amp;gt;t)\); that is, given the event that \(X_1\) is greater than a threshold \(t\), what is the probability that \(X_2\) is also greater than \(t\).&lt;/p&gt;

&lt;!-- ```r
rmvnorm(10000, sigma = matrix(c(1, 0.5, 0.5, 1), nrow = 2)) %&gt;% 
    data.frame() %&gt;% 
    ggplot(aes(x = X1, y = X2)) +
    geom_point(alpha = 0.2) +
    geom_hline(yintercept = c(1, 2, 3), color = &#34;red&#34;, alpha = 0.8) +
    geom_vline(xintercept = c(1, 2, 3), color = &#34;red&#34;, alpha = 0.8) +
    xlab(latex2exp::TeX(&#34;X_1&#34;)) +
    ylab(latex2exp::TeX(&#34;X_2&#34;))
ggsave(&#34;gaussian_tail_dep.png&#34;, width = 4, height = 4)    
``` --&gt;

&lt;figure&gt;
    &lt;img src=&#34;gaussian_tail_dep.png&#34; alt=&#34;Tail independence of bivariate Gaussian distributions.&#34; width=&#34;350&#34;/&gt;
    &lt;figcaption&gt;Figure 3: Tail independence of bivariate Gaussian distributions. Adapted from Donnelly and Embrechts (2010).&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- ```
sigma &lt;- matrix(c(1, 0.5, 0.5, 1), nrow = 2)
pmvnorm(lower = c(1, 1), sigma = sigma) / pnorm(1, lower.tail = F)
pmvnorm(lower = c(2, 2), sigma = sigma) / pnorm(2, lower.tail = F)
pmvnorm(lower = c(3, 3), sigma = sigma) / pnorm(3, lower.tail = F)
``` --&gt;

&lt;p&gt;Figure 3 shows 10,000 random samples from the distribution.
For \(t \in \{1,2,3\}\), the probability can be visually estimated: among the points to the right of \(x=t\), how many of them are above \(y=t\).
It appears that the probability decreases as \(t\) increases.
A further numerical calculation gives&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;\(\mathbb{P}(X_2&amp;gt;1 | X_1&amp;gt;1) = 0.39, \)&lt;/li&gt;
&lt;li&gt;\(\mathbb{P}(X_2&amp;gt;2 | X_1&amp;gt;2) = 0.18, \)&lt;/li&gt;
&lt;li&gt;\(\mathbb{P}(X_2&amp;gt;3 | X_1&amp;gt;3) = 0.06. \)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It can be shown that
$$\lim_{t \to +\infty}\mathbb{P}(X_2&amp;gt;t | X_1&amp;gt;t) = 0. $$&lt;/p&gt;

&lt;p&gt;Interestingly, although \(X_1\) and \(X_2\) are correlated, they behave like independent random variables in the extremes.
This behavior is called (upper) tail independence.&lt;/p&gt;

&lt;p&gt;Formally, the coefficients of lower and upper tail dependence are defined as follows.
\begin{align}
\lambda_l &amp;amp;=
\lim_{q \to 0^+}
\mathbb{P} (X_2 \leq F_2^{-1}(q) | X_1 \leq F_1^{-1}(q)),
\newline
\lambda_u &amp;amp;=
\lim_{q \to 1^-}
\mathbb{P} (X_2 &amp;gt; F_2^{-1}(q) | X_1 &amp;gt; F_1^{-1}(q)),
\end{align}
where \( F_j^{-1} \) is the quantile function of \(X_j\).
A simple derivation shows that the coefficient of lower tail dependence can be expressed by the copula:
\begin{align}
\lambda_l
&amp;amp;=
\lim_{q \to 0^+}
\mathbb{P} (U_2 \leq q | U_1 \leq q)
\newline
&amp;amp;=
\lim_{q \to 0^+}
\frac
{\mathbb{P} (U_1 \leq q, U_2 \leq q)}
{\mathbb{P} (U_1 \leq q)}
\newline
&amp;amp;=
\lim_{q \to 0^+}
\frac{C(q, q)}{q}.
\end{align}
Similarly for the upper tail:
$$
\lambda_u =
\lim_{q \to 0^+}
\frac{\widehat{C}(q, q)}{q}.
$$
In Figure 1, t, Joe, and Gumbel copulas have upper tail dependence; t and MTCJ copulas have lower tail dependence.&lt;/p&gt;

&lt;p&gt;As a digression, the &lt;a href=&#34;https://en.wikipedia.org/wiki/Financial_crisis_of_2007%E2%80%932008&#34;&gt;2007&amp;ndash;2008 financial crisis&lt;/a&gt; is partially caused by the misuse of the Gaussian copula model.
See &lt;a href=&#34;https://www.wired.com/2009/02/wp-quant/&#34;&gt;Salmon (2009)&lt;/a&gt; and &lt;a href=&#34;http://www.macs.hw.ac.uk/~cd134/2010/donemb.pdf&#34;&gt;Donnelly and Embrechts (2010)&lt;/a&gt; for details.
One of the main disadvantages of the model is that it does not adequately model the occurrence
of defaults in the underlying portfolio of corporate bonds.
In times of crisis, corporate defaults occur in clusters, so that if one company defaults then it is likely that other companies also default within a short period.
However, under the Gaussian copula model, company defaults become
independent as their size of default increases, which leads to model inadequacy.&lt;/p&gt;

&lt;!-- ## Multivariate copula construction

Multivariate Gaussian and t copulas, Archimedean copulas, and vine copulas.
 --&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Donnelly, C., &amp;amp; Embrechts, P. (2010). The devil is in the tails: actuarial mathematics and the subprime mortgage crisis. ASTIN Bulletin: The Journal of the IAA, 40(1), 1-33.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Joe, H. (2014). Dependence modeling with copulas. Chapman and Hall/CRC.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Salmon, F. (2009). Recipe for disaster: the formula that killed Wall Street. February 23 2009, Wired Magazine.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Schmidt, T. (2007). Coping with copulas. Copulas-From theory to application in finance, 3-34.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;script&gt;
   window.PlotlyConfig = {MathJaxConfig: &#39;local&#39;}
&lt;/script&gt;
&lt;script src=&#34;https://cdn.plot.ly/plotly-latest.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;plotly_figure.js&#34;&gt;&lt;/script&gt;
</description>
    </item>
    
    <item>
      <title>Traveling Salesman Problem and Approximation Algorithms</title>
      <link>https://bochang.me/blog/posts/tsp/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bochang.me/blog/posts/tsp/</guid>
      <description>

&lt;p&gt;One of my research interests is a graphical model structure learning problem in multivariate statistics.
I have been recently studying and trying to borrow ideas from approximation algorithms, a research field that tackles difficult combinatorial optimization problems.
This post gives a brief introduction to two approximation algorithms for the (metric) traveling salesman problem: the double-tree algorithm and Christofides’ algorithm.
The materials are mainly based on &amp;sect;2.4 of Williamson and Shmoys (2011).&lt;/p&gt;

&lt;h2 id=&#34;1-approximation-algorithms&#34;&gt;1. Approximation algorithms&lt;/h2&gt;

&lt;p&gt;In combinatorial optimization, most interesting problems are NP-hard and do not have polynomial-time algorithms to find optimal solutions (yet?).
Approximation algorithms are efficient algorithms that find approximate solutions to such problems.
Moreover, they give provable guarantees on the distance of the approximate solution to the optimal ones.&lt;/p&gt;

&lt;p&gt;We assume that there is an objective function associated with an optimization problem.
An optimal solution to the problem is one that minimizes the value of this objective function. The value of the optimal solution is often denoted by \(\mathrm{OPT}\).&lt;/p&gt;

&lt;p&gt;An \(\alpha\)-approximation algorithm for an optimization problem is a polynomial-time algorithm that for all instances of the problem produces a solution, whose value is within a factor of \(\alpha\) of \(\mathrm{OPT}\), the value of an optimal solution. The factor \(\alpha\) is called the approximation ratio.&lt;/p&gt;

&lt;h2 id=&#34;2-traveling-salesman-problem&#34;&gt;2. Traveling salesman problem&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&#34;https://en.wikipedia.org/wiki/Travelling_salesman_problem&#34;&gt;traveling salesman problem&lt;/a&gt; (TSP) is NP-hard and one of the most well-studied combinatorial optimization problems.
It has broad applications in logistics, planning, and DNA sequencing.
In plain words, the TSP asks the following question:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city and returns to the origin city?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Formally, for a set of cities \([n] = \{1, 2, \ldots, n \}\), an \(n\)-by-\(n\) matrix \(C = (c_{ij})\), where \(c_{ij} \geq 0 \) specifies the cost of traveling from city \(i\) to city \(j\).
By convention, we assume \(c_{ii} = 0\) and \(c_{ij} = c_{ji}\), meaning that the cost of traveling from city \(i\) to city \(j\) is equal to the cost of traveling from city \(j\) to city \(i\).
Furthermore, we only consider the &lt;strong&gt;metric TSP&lt;/strong&gt; in this article; that is,
the &lt;a href=&#34;https://en.wikipedia.org/wiki/Triangle_inequality&#34;&gt;triangle inequality&lt;/a&gt; holds for any \(i,j,k\):
$$
c_{ik} \leq c_{ij} + c_{jk}, \quad \forall i, j, k \in [n].
$$&lt;/p&gt;

&lt;p&gt;Given a permutation \(\sigma\) of \([n]\), a tour traverses the cities in the order \(\sigma(1), \sigma(2), \ldots, \sigma(n)\).
The goal is to find a tour with the lowest cost, which is equal to
$$
c_{\sigma(n) \sigma(1)} + \sum_{i=1}^{n-1} c_{\sigma(i) \sigma(i+1)}.
$$&lt;/p&gt;

&lt;h2 id=&#34;3-double-tree-algorithm&#34;&gt;3. Double-tree algorithm&lt;/h2&gt;

&lt;p&gt;We first describe a simple algorithm called the double-tree algorithm and prove that it is a 2-approximation algorithm.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Double-tree algorithm&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Find a minimum spanning tree \(T\).&lt;/li&gt;
&lt;li&gt;Duplicate the edges of \(T\). Find an Eulerian tour.&lt;/li&gt;
&lt;li&gt;Shortcut the Eulerian tour.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;Figure 1 shows the algorithm on a simple five-city instance.
We give a step-by-step explanation of the algorithm.
&lt;figure&gt;
    &lt;img src=&#34;dbl_tree.jpg&#34; alt=&#34;Double-tree algorithm&#34; width=&#34;350&#34;/&gt;
    &lt;figcaption&gt;Figure 1: Double-tree algorithm.&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/p&gt;

&lt;p&gt;A &lt;a href=&#34;https://en.wikipedia.org/wiki/Spanning_tree&#34;&gt;spanning tree&lt;/a&gt; of an undirected graph is a subgraph that is a tree and includes all of the nodes.
A &lt;a href=&#34;https://en.wikipedia.org/wiki/Minimum_spanning_tree&#34;&gt;minimum spanning tree&lt;/a&gt; of a weighted graph is a spanning tree for which the total edge cost is minimized.
There are several polynomial-time algorithms for finding a minimum spanning tree, e.g., &lt;a href=&#34;https://en.wikipedia.org/wiki/Prim%27s_algorithm&#34;&gt;Prim&amp;rsquo;s algorithm&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/Kruskal%27s_algorithm&#34;&gt;Kruskal&amp;rsquo;s algorithm&lt;/a&gt;, and the &lt;a href=&#34;https://en.wikipedia.org/wiki/Reverse-delete_algorithm&#34;&gt;reverse-delete algorithm&lt;/a&gt;.
Figure 1a shows a minimum spanning tree \(T\).&lt;/p&gt;

&lt;p&gt;There is an important relationship between the minimum spanning tree problem and the traveling salesman problem.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Lemma 1.&lt;/strong&gt; For any input to the traveling salesman problem, the cost of the optimal tour is at least the cost of the minimum spanning tree on the same input.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The proof is simple. Deleting any edge from the optimal tour results in a spanning tree, the cost of which is at least the cost of the minimum spanning tree.
Therefore, the cost of the minimum spanning tree \(T\) in Figure 1(a) is at most \( \mathrm{OPT}\).&lt;/p&gt;

&lt;p&gt;Next, each edge in the minimum spanning tree is replaced by two copies of itself, as shown in Figure 1b.
The resulting (multi)graph is Eulerian.
A graph is said to be &lt;a href=&#34;https://en.wikipedia.org/wiki/Eulerian_path&#34;&gt;Eulerian&lt;/a&gt; if there exists a tour that visits every edge exactly once.
A graph is Eulerian if and only if it is connected and each node has an even degree.
Given an Eulerian graph, it is easy to construct a traversal of the edges.
For example, a possible Eulerian tour in Figure 1b is 1&amp;ndash;3&amp;ndash;2&amp;ndash;3&amp;ndash;4&amp;ndash;5&amp;ndash;4&amp;ndash;3&amp;ndash;1.
Moreover, since the edges are duplicated from the minimum spanning tree, the Eulerian tour has cost at most \(2 \, \mathrm{OPT}\).&lt;/p&gt;

&lt;p&gt;Finally, given the Eulerian tour, we remove all but the first occurrence of each node in the sequence; this step is called &lt;strong&gt;shortcutting&lt;/strong&gt;.
By the triangle inequality, the cost of the shortcut tour is at most the cost of the Eulerian tour, which is not greater than \(2 \, \mathrm{OPT}\).
In Figure 1c, the shortcut tour is 1&amp;ndash;3&amp;ndash;2&amp;ndash;4&amp;ndash;5&amp;ndash;1.
When going from node 2 to node 4 by omitting node 3, we have \(c_{24} \leq c_{23} + c_{34}\).
Similarly, when skipping nodes 4 and 3, \(c_{51} \leq c_{54} + c_{43} + c_{31}\).&lt;/p&gt;

&lt;p&gt;Therefore, we have analyzed the approximation ratio of the double-tree algorithm.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem 1.&lt;/strong&gt; The double-tree algorithm for the metric traveling salesman problem is a 2-approximation algorithm.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;4-christofides-algorithm&#34;&gt;4. Christofides&amp;rsquo; algorithm&lt;/h2&gt;

&lt;p&gt;The basic strategy of the double-tree algorithm is to construct an Eulerian tour whose total cost is at most \(\alpha \, \mathrm{OPT}\), then shortcut it to get an \(\alpha\)-approximation solution.
The same strategy can be carried out to yield a &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt;-approximation algorithm.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Christofides&amp;rsquo; algorithm&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Find a minimum spanning tree \(T\).&lt;/li&gt;
&lt;li&gt;Let \(O\) be the set of nodes with odd degree in \(T\). Find a minimum-cost perfect matching \(M\) on \(O\).&lt;/li&gt;
&lt;li&gt;Add the set of edges of \(M\) to \(T\). Find an Eulerian tour.&lt;/li&gt;
&lt;li&gt;Shortcut the Eulerian tour.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;Figure 2 illustrates the algorithm on a simple five-city instance of TSP.
&lt;figure&gt;
    &lt;img src=&#34;christofides.jpg&#34; alt=&#34;Christofides&#39; algorithm&#34; width=&#34;350&#34;/&gt;
    &lt;figcaption&gt;Figure 2: Christofides&amp;rsquo; algorithm.&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/p&gt;

&lt;p&gt;The algorithm starts again with the minimum spanning tree \(T\). The reason we cannot directly find an Eulerian tour is that its leaf nodes all have degrees of one.
However, by the &lt;a href=&#34;https://en.wikipedia.org/wiki/Handshaking_lemma&#34;&gt;handshaking lemma&lt;/a&gt;, there is an even number of odd-degree nodes.
If these nodes can be paired up, then it becomes an Eulerian graph and we can proceed as before.&lt;/p&gt;

&lt;p&gt;Let \(O\) be the set of odd-degree nodes in \(T\).
To pair them up, we want to find a collection of edges that contain each node in \(O\) exactly once.
This is called a &lt;a href=&#34;https://en.wikipedia.org/wiki/Matching_(graph_theory)&#34;&gt;perfect matching&lt;/a&gt; in graph theory.
Given a complete graph (on an even number of nodes) with edge costs,
there is a polynomial-time algorithm to find the perfect matching of the minimum total cost, known as the &lt;a href=&#34;https://en.wikipedia.org/wiki/Blossom_algorithm&#34;&gt;blossom algorithm&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For the minimum spanning tree \(T\) in Figure 2a, \( O = \{1, 2, 3, 5\}\).
The minimum-cost perfect matching \(M\) on the complete graph induced by \(O\) is shown in Figure 2b.
Adding the edges of \(M\) to \(T\), the result is an Eulerian graph, since we have added a new edge incident to each odd-degree node in \(T\).
The remaining steps are the same as in the double-tree algorithm.&lt;/p&gt;

&lt;p&gt;We want to show that the Eulerian graph has total cost of at most &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt; \(\mathrm{OPT}\).
Since the total cost of the minimum spanning tree \(T\) is at most \(\mathrm{OPT}\), we only need to show that the perfect matching \(M\) has cost at most &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt; \(\mathrm{OPT}\).&lt;/p&gt;

&lt;p&gt;We start with the optimal tour on the entire set of cities, the cost of which is \(\mathrm{OPT}\) by definition.
Figure 3a presents a simplified illustration of the optimal tour; the solid circles represent nodes in \(O\).
By omitting the nodes that are not in \(O\) from the optimal tour, we get a tour on \(O\), as shown in Figure 3b.
By the shortcutting argument again, the total cost of the tour on \(O\) is at most \(\mathrm{OPT}\).
Next, color the edges yellow and green, alternating colors as the tour is traversed, as illustrated in Figure 3c.
This partitions the edges into two sets: the yellow set and the green set; each is a perfect matching on \(O\).
Since the total cost of the two matchings is at most \(\mathrm{OPT}\), the cheaper one has cost at most &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt; \(\mathrm{OPT}\).
In other words, there exists a perfect matching on \(O\) of cost at most &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt; \(\mathrm{OPT}\).
Therefore, the minimum-cost perfect matching must have cost not greater than &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt; \(\mathrm{OPT}\).
This completes the proof of the following theorem.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem 2.&lt;/strong&gt; Christofides&amp;rsquo; algorithm for the metric traveling salesman problem is a &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt;-approximation algorithm.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;figure&gt;
    &lt;img src=&#34;matching.jpg&#34; alt=&#34;minimum-cost perfect matching&#34; width=&#34;350&#34;/&gt;
    &lt;figcaption&gt;Figure 3: Minimum-cost perfect matching.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- 

## Why metric TSP?

Without the metric constraint, not only the TSP is hard, even finding an approximation algorithm for the TSP is hard.


A [Hamiltonian cycle](https://en.wikipedia.org/wiki/Hamiltonian_path) in an undirected graph is a cycle that visits each node exactly once.
It is NP-complete to decide whether a given undirected graph \\( G = (V, E) \\) has a Hamiltonian cycle.
If there were to exist a 2-approximation algorithm for the TSP, then this algorithm could be used to decide whether a Hamiltonian cycle exists.

Given an input to the Hamiltonian cycle problem \\( G = (V, E) \\), construct an input to the TSP by setting
$$
c_{ij}=
\begin{cases}
1   &amp;\mbox{if } (i, j) \in E \newline
n+2 &amp;\mbox{otherwise}
\end{cases}
$$
where \\(n = |V|\\) is the number of nodes in \\(G\\).
If the is a Hamiltonian cycle in \\(G\\), then there is a tour of cost \\(n\\); otherwise each tour costs at least \\(2n+1\\), which consists of \\(n-1\\) edges in \\(E\\) and one edge not in \\(E\\).

Run the 2-approximation algorithm on the new TSP input; 
if the computed tour has cost at most \\(2n\\), then there exists a Hamiltonian cycle in \\(G\\); otherwise, there does not.


&gt; **Theorem 3.** For any \\(\alpha &gt; 1\\), there does not exist an \\(\alpha\\)-approximation algorithm for the traveling salesman problem, provided \\(\mathrm{P} \neq \mathrm{NP}\\). --&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Williamson, D. P., &amp;amp; Shmoys, D. B. (2011). The Design of Approximation Algorithms. Cambridge University Press.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Stochastic Bandits and UCB Algorithm</title>
      <link>https://bochang.me/blog/posts/bandits/</link>
      <pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://bochang.me/blog/posts/bandits/</guid>
      <description>

&lt;p&gt;In our recent paper &lt;em&gt;Vine Copula Structure Learning via Monte Carlo Tree Search&lt;/em&gt; (AISTATS 2019), we apply the UCT (Upper Confidence bounds applied to Trees) algorithm to find an approximate solution to an NP-hard structure learning problem in statistics.
The UCT algorithm is based on the UCB1 (Upper Confidence Bound) algorithm for the stochastic bandit problem.&lt;/p&gt;

&lt;p&gt;Thankfully, I audited &lt;a href=&#34;https://www.cs.ubc.ca/~nickhar/&#34;&gt;Prof. Nick Harvey&lt;/a&gt;&amp;rsquo;s &lt;a href=&#34;https://www.cs.ubc.ca/~nickhar/F18-531/&#34;&gt;learning theory course&lt;/a&gt; this semester.
In one lecture, he gave a clear exposition of the multi-armed bandit problem and algorithms.
It deepened my understanding of the theoretical properties of the UCB1 algorithm.
This blog post is mostly a transcription of the lecture; it gives an overview of the regret bound analysis of the explore-first algorithm and UCB1 algorithm. The material is also based on the first chapter of Slivkins (2017).&lt;/p&gt;

&lt;h2 id=&#34;1-problem-formulation&#34;&gt;1. Problem formulation&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&#34;https://en.wikipedia.org/wiki/Multi-armed_bandit&#34;&gt;multi-armed bandit problem&lt;/a&gt; has many practical applications including clinical trials, financial portfolio design, and online advertising.
The name comes from imagining a gambler at a row of slot machines (sometimes known as &amp;ldquo;one-armed bandits&amp;rdquo;), each with a lever.
In each round, the gambler picks a machine to play, then the reward for the chosen machine is observed.
The objective of the gambler is to maximize the sum of rewards earned through a sequence of lever pulls.
In the rest of the post, we use the term &amp;ldquo;arm&amp;rdquo; as a synonym for a slot machine.&lt;/p&gt;

&lt;p&gt;In this post, we focus on the &lt;strong&gt;stochastic bandit problem&lt;/strong&gt;, where the rewards for each arm are i.i.d. from a probability distribution specific to that arm.
Another variant of the multi-armed bandit problem is called the &lt;strong&gt;adversarial bandit problem&lt;/strong&gt;, where an adversary chooses the reward for each arm while the player chooses an arm.&lt;/p&gt;

&lt;p&gt;The fundamental tradeoff the gambler faces is between &lt;strong&gt;exploration&lt;/strong&gt; and &lt;strong&gt;exploitation&lt;/strong&gt;.
In machine learning, exploration stands for the acquisition of new knowledge, and exploitation refers to an optimized decision based on existing knowledge.
In the case of the multi-armed bandit problem, the gambler needs to decide between trying different arms to get more information about their rewards and playing the arm that has the highest average reward so far.&lt;/p&gt;

&lt;p&gt;The following notations are used throughout the post.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;\(K\) is the total number of arms and \(T\) is the total number of rounds, both are known in advance. Arms are denoted by \(a \in [K]\), rounds by \(t \in [T]\). (The bracket notation \([n]\) denotes the first \(n\) positive integers \([n] := \{1, 2, \ldots, n\}\).)&lt;/li&gt;
&lt;li&gt;The reward for arm \(a\) is i.i.d. from \(\mathcal{D}_a\), which is a distribution supported on \([0,1]\). The expected reward of arm \(a\) is denoted by \(\mu(a) := \int_0^1 x \, \mathrm{d}\mathcal{D}_a(x)\).&lt;/li&gt;
&lt;li&gt;The best expected reward is denoted by \(\mu^* := \max_{a \in [K]} \mu(a)\), and the best arm is \(a^* = \operatorname{argmax}_{a \in [K]} \mu(a)\).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The (cumulative) &lt;strong&gt;regret&lt;/strong&gt; in round \(t\) is defined as
$$ R(t) =  \mu^* t  - \sum_{s=1}^t \mu(a_s), $$
where \(a_s\) is the chosen arm in round \(s\).
The regret is the difference between the sum of rewards associated with the optimal arm and the sum of expected rewards by an algorithm.
The goal of the algorithm is to minimize regret.
Note that \(a_s\) is a random quantity, since it may depend on the randomness in rewards and/or the algorithm.
Therefore the regret \(R(t)\) is also random and we are interested in the expected regret \(\mathbb{E}[R(t)]\) or \(\mathbb{E}[R(T)]\).&lt;/p&gt;

&lt;p&gt;It may be a good time now to review &lt;a href=&#34;https://en.wikipedia.org/wiki/Hoeffding%27s_inequality&#34;&gt;Hoeffding&amp;rsquo;s inequality&lt;/a&gt;, an important concentration inequality widely used in machine learning theory.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Hoeffding&amp;rsquo;s inequality&lt;/strong&gt;&lt;br /&gt;
Let \(X_1, \ldots, X_n\) be independent random variables and let \(\bar{X}=\frac{1}{n}\sum_{i=1}^n X_i\). Assume \(0 \leq X_i \leq 1\) almost surely. Then, for any \(t&amp;gt;0\),
$$\mathbb{P}(|\bar{X} - \mathbb{E}[\bar{X}]| &amp;gt; t) \leq 2 \exp (-2nt^2).$$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;2-explore-first-algorithm&#34;&gt;2. Explore-first algorithm&lt;/h2&gt;

&lt;p&gt;A simple idea is to explore arms uniformly and pick an empirically best arm for exploitation.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Explore-first algorithm&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Exploration phase:     Try each arm \(N\) times. Let \(\bar\mu(a)\) be the average reward for arm \(a\);&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Exploitation phase: Select arm \(\hat{a}\) with the highest average reward \(\hat{a} = \operatorname{argmax}_{a \in [K]} \bar\mu(a)\). Play arm \(\hat{a}\) in all remaining rounds.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;The parameter \(N\) is fixed in advance; it will be chosen later as a function of \(T\) and \(K\).&lt;/p&gt;

&lt;h3 id=&#34;2-1-regret-bound&#34;&gt;2.1 Regret bound&lt;/h3&gt;

&lt;p&gt;Our goal is to give an upper bound of the expected regret \(\mathbb{E}[R(T)]\) as a function of \(K\) and \(T\):
$$
\mathbb{E}[R(T)]=O \big(T^{2 / 3} (K \log T)^{1 / 3} \big).
$$&lt;/p&gt;

&lt;p&gt;To facilitate our analysis, we define the &lt;strong&gt;clean event&lt;/strong&gt; \(C\) to be the event that \(\bar\mu(a)\) is close to \(\mu(a)\) for all arms:
$$
C = \{ |\bar\mu(a) - \mu(a)| \leq r, \forall a \in [K] \},
$$
where \(r\) is called the &lt;strong&gt;confidence radius&lt;/strong&gt;.
The &lt;strong&gt;bad event&lt;/strong&gt; \(\bar{C}\) is the complement of the clean event.
By the &lt;a href=&#34;https://en.wikipedia.org/wiki/Law_of_total_expectation&#34;&gt;law of total expectation&lt;/a&gt;,
$$
\mathbb{E}[R(T)] =
\mathbb{E}[R(T) | C]
\mathbb{P}[C]
+
\mathbb{E}[R(T) | \bar{C}]
\mathbb{P}[\bar{C}].
$$&lt;/p&gt;

&lt;p&gt;First of all, we want to make sure \(\mathbb{P}[\bar{C}]\) is small.
In other words, the average reward \(\bar\mu(a)\) should be a good estimate of the true expected reward \(\mu(a)\).
By Hoeffding&amp;rsquo;s inequality, the deviation of the average reward from the true expected reward can be quantified as follows:&lt;/p&gt;

&lt;p&gt;$$
\mathbb{P}( |\bar\mu(a) - \mu(a)| &amp;gt; r) \leq 2 \exp (-2Nr^2), \quad \forall a \in [K].
$$&lt;/p&gt;

&lt;p&gt;We want to bound this probability by a sufficiently small number, say \(2/T^4\). This can be achieved by setting the confidence radius \(r = \sqrt{\frac{2 \log T}{N}}\):
$$
\mathbb{P}( |\bar\mu(a) - \mu(a)| &amp;gt; r) \leq \frac{2}{T^4}, \quad \forall a \in [K].
$$
Note that the choice of \(T^4\) is somewhat arbitrary; the exponent only affects the multiplicative constant of \(r\).&lt;/p&gt;

&lt;p&gt;Using a &lt;a href=&#34;https://en.wikipedia.org/wiki/Boole%27s_inequality&#34;&gt;union bound&lt;/a&gt;, we can find an upper bound of the probability of the bad event.
$$
\begin{align}
\mathbb{P}(\bar{C})
&amp;amp;=
\mathbb{P} \big(\{ \exists a \in [K] \ \text{s.t.}\ |\bar\mu(a) - \mu(a)| &amp;gt; r \} \big)
\newline
&amp;amp;=
\mathbb{P} \big(\bigcup_{a \in [K]}\{|\bar\mu(a) - \mu(a)| &amp;gt; r \} \big)
\newline
&amp;amp;\leq \sum_{a \in [K]} \mathbb{P} (|\bar\mu(a) - \mu(a)| &amp;gt; r )
\newline
&amp;amp;\leq
\frac{2K}{T^4}
\newline
&amp;amp;\leq
\frac{2}{T^3}.
\end{align}
$$
The last inequality is because each arm is explored at least once, i.e., \(T \geq K\).&lt;/p&gt;

&lt;p&gt;Next, we focus on \(\mathbb{E}[R(T) | C]\).
By definition, \(\bar\mu(\hat{a}) \geq \bar\mu(a^*)\).
Given the clean event happens,
an upper bound of \(\mu(a^*) - \mu(\hat{a}) \) can be obtained:
$$
\begin{align}
\mu(a^*) - \mu(\hat{a})
&amp;amp;\leq
\mu(a^*) - \mu(\hat{a}) + \bar\mu(\hat{a}) - \bar\mu(a^*)
\newline
&amp;amp;=
\big(\mu(a^*) - \bar\mu(a^*)\big) + \big(\bar\mu(\hat{a}) - \mu(\hat{a}) \big)
\newline
&amp;amp;\leq 2r.
\end{align}
$$
Intuitively, it indicates that conditioning on the clean event, the chosen arm \(\hat{a}\) cannot be much worse than \(a^*\).&lt;/p&gt;

&lt;p&gt;There are \(NK\) rounds in the exploration phase, and each round has at most regret of 1; there are \(T - NK\) rounds in the exploitation phase and the regret incurred in each round is bounded by \(2r\).
As a result, the regret in round \(T\) can be bounded by
$$
\begin{align}
\mathbb{E}[R(T) | C]
&amp;amp;\leq NK + (T - NK) 2r
\newline
&amp;amp;\leq NK + 2Tr
\newline
&amp;amp;= NK + 2T \sqrt{\frac{2 \log T}{N}}.
\end{align}
$$
Since we can choose the number of rounds in the exploration phase,
the right-hand side can be minimized by setting
\( N = (T/K)^{2 / 3} (2\log T)^{1 / 3} \).
Therefore,
$$
\mathbb{E}[R(T) | C]
\leq
T^{2 / 3} (2K\log T)^{1 / 3}.
$$&lt;/p&gt;

&lt;p&gt;So far, we have&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;\(\mathbb{E}[R(T) | C]
\leq
T^{2 / 3} (2K \log T)^{1 / 3}
\);&lt;/li&gt;
&lt;li&gt;\( \mathbb{P}[C] \leq 1 \);&lt;/li&gt;
&lt;li&gt;\( \mathbb{E}[R(T) | \bar{C}] \leq T \), since there are in total \(T\) rounds, each round incurs at most regret of 1;&lt;/li&gt;
&lt;li&gt;\(\mathbb{P}[\bar{C}] \leq 2 / T^4 \).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Putting everything together,
$$
\begin{align}
\mathbb{E}[R(T)] &amp;amp;=
\mathbb{E}[R(T) | C]
\mathbb{P}[C]
+
\mathbb{E}[R(T) | \bar{C}]
\mathbb{P}[\bar{C}]
\newline
&amp;amp;\leq
T^{2 / 3} (2K\log T)^{1 / 3}
+
T \cdot \frac{2}{T^3}
\newline
&amp;amp;= O \big(T^{2 / 3} (K \log T)^{1 / 3} \big).
\end{align}
$$&lt;/p&gt;

&lt;h2 id=&#34;3-upper-confidence-bound-algorithm&#34;&gt;3. Upper confidence bound algorithm&lt;/h2&gt;

&lt;p&gt;The problem with the explore-first algorithm is that each arm is explored for the same number of rounds, which causes inefficiency.
In other words, the exploration schedule should depend on the history of the observed rewards.
Instead of using the same confidence radius for any arm in any round, we denote the confidence radius for arm \(a\) at time \(t\) by \(r_t(a)\).
Let \(n_t(a)\) be the number of times arm \(a\) is selected in rounds \(1, 2, \ldots, t\) and \(\bar\mu_t(a)\)  be the average reward of arm \(a\) up to time \(t\).
The &lt;strong&gt;upper confidence bound&lt;/strong&gt; is defined as
$$
\mathrm{UCB}_t(a) = \bar\mu_t(a) + r_t(a),
$$
where \( r_t(a) = \sqrt{\frac{2 \log T}{n_t(a)}} \).&lt;/p&gt;

&lt;p&gt;The UCB1 algorithm chooses the best arm based on an optimistic estimate. The algorithm is as follows.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;UCB1 algorithm&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Try each arm once;&lt;/li&gt;
&lt;li&gt;In round \(t\), pick \( a_t = \operatorname{argmax}_{a \in [K]} \mathrm{UCB}_t(a)\).&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;Unlike the explore-first algorithm, there is no clear exploration/exploitation phase. However, the definition of the upper confidence bound manifests the exploration-exploitation tradeoff: \(\bar\mu_t(a)\) encourages the exploitation of high reward arms, while \(r_t(a)\) encourages the exploration of less played arms.&lt;/p&gt;

&lt;h3 id=&#34;3-1-regret-bound&#34;&gt;3.1 Regret bound&lt;/h3&gt;

&lt;p&gt;The regret bound of the UCB1 algorithm is
$$
\mathbb{E}[R(t)] = O \big(\sqrt{Kt \log T} \big),
\quad
\forall t \in [T].
$$
The idea of the analysis is the same as before: define a clean event \(C\), obtain upper bounds of \(\mathbb{P}[\bar{C}]\) and \(\mathbb{E}[R(t)|C]\), and finally bound \(\mathbb{E}[R(t)]\).&lt;/p&gt;

&lt;p&gt;Since the confidence radius now depends on \(t\) as well, we need a more refined definition of the &lt;strong&gt;clean event&lt;/strong&gt;:
$$
C = \{|\bar\mu_t(a) - \mu(a)| \leq r_t(a), \forall a \in [K], \forall t \in [T] \}.
$$
Applying Hoeffding&amp;rsquo;s inequality and a union bound (and ignoring some technicalities),
$$
\mathbb{P}[\bar{C}] \leq \frac{2KT}{T^4} \leq \frac{2}{T^2}.
$$&lt;/p&gt;

&lt;p&gt;Now we focus on \(\mathbb{E}[R(t)|C]\) and assume the clean event holds.
By definition, \( \mathrm{UCB}_t(a_t) \geq \mathrm{UCB}_t(a^*) \) for any round \(t \in [T]\).
As a result,&lt;/p&gt;

&lt;p&gt;$$
\begin{align}
\mu(a^*) - \mu(a_t)
&amp;amp;\leq
\mu(a^*) - \mu(a_t) + \mathrm{UCB}_t(a_t) - \mathrm{UCB}_t(a^*)
\newline
&amp;amp;= \big(\mu(a^*) - \mathrm{UCB}_t(a^*)\big) + \big(\mathrm{UCB}_t(a_t) - \mu(a_t) \big),
\end{align}
$$
where
$$
\mu(a^*) - \mathrm{UCB}_t(a^*)
=\mu(a^*) - \bar\mu_t(a^*) - r_t(a^*)
\leq 0,
$$
and
$$
\mathrm{UCB}_t(a_t) - \mu(a_t)
=\bar\mu_t(a_t) - \mu(a_t) + r_t(a_t)
\leq 2 r_t(a_t).
$$
Therefore,
$$
\mu(a^*) - \mu(a_t)
\leq
2 r_t(a_t)
= 2 \sqrt{\frac{2 \log T}{n_t(a_t)}}.
$$&lt;/p&gt;

&lt;p&gt;For each arm \(a\) and a given time \(t \in [T]\), consider the last round \(t_0 \leq t\) when this arm is chosen.
Since arm \(a\) is never played between round \(t_0\) and round \(t\), we have \(n_{t_0}(a) = n_t(a)\).
Applying the above inequality to arm \(a\) and round \(t_0\),
$$
\mu(a^*) - \mu(a) \leq 2 \sqrt{\frac{2 \log T}{n_t(a)}},
\quad
\forall t \in [T].
$$
Intuitively it means that, under the clean event, if an arm is selected many times, it cannot be much worse than the best arm; or equivalently, if an arm is much worse than the best arm, it won&amp;rsquo;t be selected many times.&lt;/p&gt;

&lt;p&gt;The regret in round \(t\) is thus bounded by
$$
R(t) = \sum_{a \in [K]}
n_t(a) \big(\mu(a^*) - \mu(a)\big)
\leq
2 \sqrt{2 \log T}
\sum_{a \in [K]}
\sqrt{n_t(a)}.
$$
Since the square root function is concave, by &lt;a href=&#34;https://en.wikipedia.org/wiki/Jensen%27s_inequality&#34;&gt;Jensen&amp;rsquo;s inequality&lt;/a&gt;,
$$
\sum_{a \in [K]}
\sqrt{n_t(a)}
= K \sum_{a \in [K]}
\frac{1}{K} \sqrt{n_t(a)}
\leq
K
\sqrt{\frac{1}{K}\sum_{a \in [K]} n_t(a)}
= \sqrt{Kt}.
$$
Therefore,
$$
\mathbb{E}[R(t)|C] \leq 2 \sqrt{2 Kt \log T}.
$$&lt;/p&gt;

&lt;p&gt;Finally, much like what we did for the explore-first algorithm, the expected regret in round \(t\) can be bounded by
$$
\begin{align}
\mathbb{E}[R(t)] &amp;amp;=
\mathbb{E}[R(t) | C]
\mathbb{P}[C]
+
\mathbb{E}[R(t) | \bar{C}]
\mathbb{P}[\bar{C}]
\newline
&amp;amp;\leq
2 \sqrt{2 Kt \log T}
+
t \cdot \frac{2}{T^2}
\newline
&amp;amp;= O \big(\sqrt{Kt \log T} \big),
\quad
\forall t \in [T].
\end{align}
$$&lt;/p&gt;

&lt;h3 id=&#34;3-2-an-instance-dependent-regret-bound&#34;&gt;3.2 An instance-dependent regret bound&lt;/h3&gt;

&lt;p&gt;We can also obtain another regret bound using the inequality
$$
\mu(a^*) - \mu(a) \leq 2 \sqrt{\frac{2 \log T}{n_T(a)}}.
$$
Rearrange the terms,
$$
n_T(a) \leq \frac{8 \log T}{(\mu(a^*) - \mu(a))^2},
\quad
\text{if }
\mu(a) &amp;lt; \mu(a^*).
$$
The regret in round \(T\) is bounded by
$$
R(T) = \sum_{a \in [K]} n_T(a) \big(\mu(a^*) - \mu(a)\big)
\leq
8 \log T
\sum_{\{a \in [K]: \mu(a) &amp;lt; \mu(a^*)\}}
\frac{1}{\mu(a^*) - \mu(a)}.
$$
Therefore,
$$
\mathbb{E}[R(T)]
\leq
O(\log T)
\sum_{\{a \in [K]: \mu(a) &amp;lt; \mu(a^*)\}}
\frac{1}{\mu(a^*) - \mu(a)}.
$$&lt;/p&gt;

&lt;p&gt;This regret bound is logarithmic in \(T\), with a constant that can be arbitrarily large depending on a problem instance.
This type of regret bound is called &lt;strong&gt;instance-dependent&lt;/strong&gt;. The existence of a logarithmic regret bound is a benefit of the UCB1 algorithm compared to the explore-first algorithm, whose regret bound is polynomial in \(T\).&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Slivkins, A. (2017). Introduction to Multi-Armed Bandits. &lt;a href=&#34;http://slivkins.com/work/MAB-book.pdf&#34;&gt;http://slivkins.com/work/MAB-book.pdf&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A Few LaTeX Tips</title>
      <link>https://bochang.me/blog/posts/latex/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://bochang.me/blog/posts/latex/</guid>
      <description>

&lt;p&gt;LaTeX is a high-quality typesetting system and the de facto standard for the publication of scientific documents. However, I never got a chance to learn how to use it formally. Most of my LaTeX knowledge comes from learning by doing. As I&amp;rsquo;m working on my Ph.D. thesis, I would like to share a few LaTeX tips that I wish I had known earlier. I got most of them from working with my advisors, internship hosts, and collaborators. There is still a lot for me to learn about LaTeX. Any comments and suggestions are welcome!&lt;/p&gt;

&lt;h2 id=&#34;1-non-breaking-spaces&#34;&gt;1. Non-breaking spaces&lt;/h2&gt;

&lt;p&gt;In digital typesetting, a non-breaking space is a space character that prevents an automatic line break at its position. It is like an invisible glue between two words. There are various situations where a non-breaking space is used. For example, if the phrase &amp;ldquo;100 km&amp;rdquo; does not fit at the end of a line, the word processor may insert a line break between &amp;ldquo;100&amp;rdquo; and &amp;ldquo;km&amp;rdquo;, which is not desirable.&lt;/p&gt;

&lt;p&gt;LaTeX uses the &lt;code&gt;~&lt;/code&gt; symbol as a non-breaking space. It is usually inserted before any numeric or alphabetic reference, for example, &lt;code&gt;Figure~\ref{fig:foo}&lt;/code&gt; and &lt;code&gt;Section~\ref{sec:bar}&lt;/code&gt;. Compare the following examples:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Without a non-breaking space: &lt;code&gt;Table 3&lt;/code&gt;
&lt;img src=&#34;nonbreaking-1.png&#34; alt=&#34;without a non-breaking space&#34; /&gt;&lt;/li&gt;
&lt;li&gt;With a non-breaking space: &lt;code&gt;Table~3&lt;/code&gt;
&lt;img src=&#34;nonbreaking-2.png&#34; alt=&#34;with a non-breaking space&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;2-citations-using-citet-and-citep&#34;&gt;2. Citations using &lt;code&gt;\citet&lt;/code&gt; and &lt;code&gt;\citep&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;The &lt;code&gt;natbib&lt;/code&gt; package is commonly used for handling references in LaTeX. It is included in the style files by default for many conferences including ICML, NIPS, ICLR, etc. See &lt;a href=&#34;https://gking.harvard.edu/files/natnotes2.pdf&#34;&gt;here&lt;/a&gt; for a reference sheet for &lt;code&gt;natbib&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The two basic citation commands in &lt;code&gt;natbib&lt;/code&gt; are&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;\citet&lt;/code&gt; for &lt;strong&gt;textual&lt;/strong&gt; citations,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;\citep&lt;/code&gt; for &lt;strong&gt;parenthetical&lt;/strong&gt; citations.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The difference is that &lt;code&gt;\citet{jon90}&lt;/code&gt; prints &lt;em&gt;Jones et al. (1990)&lt;/em&gt;, while &lt;code&gt;\citep{jon90}&lt;/code&gt; prints &lt;em&gt;(Jones et al., 1990)&lt;/em&gt;. The choice depends on whether the authors are to be read as part of the sentence. According to the formatting instructions for ICLR 2019:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;When the authors or the publication are included in the sentence, the citation should not be in parenthesis (as in “See Hinton et al. (2006) for more information.”). Otherwise, the citation should be in parenthesis (as in “Deep learning shows promise to make progress towards AI (Bengio &amp;amp; LeCun, 2007).”).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The command &lt;code&gt;\cite&lt;/code&gt; should be avoided because its behavior depends on the citation format and might cause inconsistency. According to the &lt;code&gt;natbib&lt;/code&gt; documentation:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The standard LaTeX command &lt;code&gt;\cite&lt;/code&gt; should be avoided, because it behaves like &lt;code&gt;\citet&lt;/code&gt; for author-year citations, but like &lt;code&gt;\citep&lt;/code&gt; for numerical ones.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;3-mathematical-symbols&#34;&gt;3. Mathematical symbols&lt;/h2&gt;

&lt;p&gt;When writing mathematical formulas, people follow certain conventions of notations. In fact, there is an ISO standard &lt;a href=&#34;https://people.engr.ncsu.edu/jwilson/files/mathsigns.pdf&#34;&gt;ISO 80000-2&lt;/a&gt; that defines mathematical signs and symbols. I found an article titled &lt;a href=&#34;https://tug.org/TUGboat/tb18-1/tb54becc.pdf&#34;&gt;Typesetting mathematics for science and technology according to ISO 31/XI&lt;/a&gt; by Claudio Beccari. (ISO 31/XI is the precursor of ISO 80000-2.) The recommendations below are excerpts of the article. The &amp;ldquo;roman type&amp;rdquo; refers to upright letters and the &amp;ldquo;italic type&amp;rdquo; refers to sloping letters.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;a) Variables and functions are represented by one italic letter with modifiers such as subscripts, superscripts, primes, etc.&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;LaTeX&lt;/th&gt;
&lt;th&gt;Display&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;L(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(L(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;L&#39;(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(L&amp;rsquo;(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;L_{\mathrm{adversarial}}(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(L_{\mathrm{adversarial}}(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Incorrect&lt;/td&gt;
&lt;td&gt;&lt;code&gt;LOSS(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(LOSS(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Incorrect&lt;/td&gt;
&lt;td&gt;&lt;code&gt;Loss(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(Loss(x)\)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;b) Mathematical operators indicated with letters must be set in roman type.&lt;/strong&gt;
This includes the predefined operators &lt;code&gt;\exp&lt;/code&gt;, &lt;code&gt;\log&lt;/code&gt;, &lt;code&gt;\sin&lt;/code&gt;, &lt;code&gt;\tanh&lt;/code&gt;, &lt;code&gt;\det&lt;/code&gt;, &lt;code&gt;\min&lt;/code&gt;, &lt;code&gt;\inf&lt;/code&gt;, as well as user-defined operators.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;LaTeX&lt;/th&gt;
&lt;th&gt;Display&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;\sin(2x) = 2 \sin(x) \cos(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(\sin(2x) = 2 \sin(x) \cos(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Incorrect&lt;/td&gt;
&lt;td&gt;&lt;code&gt;sin(2x) = 2 sin(x) cos(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(sin(2x) = 2 sin(x) cos(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;\operatorname{softmax}(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(\operatorname{softmax}(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Incorrect&lt;/td&gt;
&lt;td&gt;&lt;code&gt;softmax(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(softmax(x)\)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;c) A particular operator, the operator of differentiation, should be set in roman type.&lt;/strong&gt;
This one is somewhat controversial. In some fields, italic type seems more common. I personally prefer roman type.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;LaTeX&lt;/th&gt;
&lt;th&gt;Display&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;\int x \mathrm{d} x&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(\int x \mathrm{d} x\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Incorrect&lt;/td&gt;
&lt;td&gt;&lt;code&gt;\int x dx&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(\int x dx\)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;d) Sub and superscripts that do not represent mathematical variables should be set in roman type.&lt;/strong&gt;
The first row is correct because \(n\) represents a variable here.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;LaTeX&lt;/th&gt;
&lt;th&gt;Display&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;S_n = \sum_{i=1}^n X_i&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\( S_n = \sum_{i=1}^n X_i \)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;L_{\mathrm{adversarial}}(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(L_{\mathrm{adversarial}}(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Incorrect&lt;/td&gt;
&lt;td&gt;&lt;code&gt;L_{adversarial}(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(L_{adversarial}(x)\)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;4-avoid-vspace&#34;&gt;4. Avoid &lt;code&gt;\vspace&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;Most conferences have strict page limits. More often than not, eight pages are not enough to adequately present a brilliant idea. If only Fermat got more space in the margin!&lt;/p&gt;

&lt;p&gt;A common trick is to use &lt;code&gt;\vspace&lt;/code&gt;. It can reduce the length of vertical space before or after a section, figure or table. However, this essentially alters the style template. Many formatting instructions explicitly forbid the use of &lt;code&gt;\vspace&lt;/code&gt;. It might even result in the rejection of the paper. From the formatting instructions for AAAI 2019:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;if your paper is obviously &amp;ldquo;squeezed&amp;rdquo; it is not going to be accepted.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Reducing the vertical spaces also makes the paper less readable for the reviewers, so it is definitely not advisable.
Many conferences support the submission of supplementary material. If the paper is too long, consider reorganizing it and moving some sections to the supplementary material.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>