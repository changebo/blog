<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bo&#39;s Blog</title>
    <link>https://bochang.me/blog/</link>
    <description>Recent content on Bo&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 10 Feb 2019 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://bochang.me/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Traveling Salesman Problem and Approximation Algorithms</title>
      <link>https://bochang.me/blog/posts/tsp/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bochang.me/blog/posts/tsp/</guid>
      <description>

&lt;p&gt;One of my research interests is a graphical model structure learning problem in multivariate statistics.
I have been recently studying and trying to borrow ideas from approximation algorithms, a research field that tackles difficult combinatorial optimization problems.
This post gives a brief introduction to two approximation algorithms for the (metric) traveling salesman problem: the double-tree algorithm and Christofides’ algorithm.
The materials are mainly based on &amp;sect;2.4 of Williamson and Shmoys (2011).&lt;/p&gt;

&lt;h2 id=&#34;1-approximation-algorithms&#34;&gt;1. Approximation algorithms&lt;/h2&gt;

&lt;p&gt;In combinatorial optimization, most interesting problems are NP-hard and do not have polynomial-time algorithms to find optimal solutions (yet?).
Approximation algorithms are efficient algorithms that find approximate solutions to such problems.
Moreover, they give provable guarantees on the distance of the approximate solution to the optimal ones.&lt;/p&gt;

&lt;p&gt;We assume that there is an objective function associated with an optimization problem.
An optimal solution to the problem is one that minimizes the value of this objective function. The value of the optimal solution is often denoted by \(\mathrm{OPT}\).&lt;/p&gt;

&lt;p&gt;An \(\alpha\)-approximation algorithm for an optimization problem is a polynomial-time algorithm that for all instances of the problem produces a solution, whose value is within a factor of \(\alpha\) of \(\mathrm{OPT}\), the value of an optimal solution. The factor \(\alpha\) is called the approximation ratio.&lt;/p&gt;

&lt;h2 id=&#34;2-traveling-salesman-problem&#34;&gt;2. Traveling salesman problem&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&#34;https://en.wikipedia.org/wiki/Travelling_salesman_problem&#34;&gt;traveling salesman problem&lt;/a&gt; (TSP) is NP-hard and one of the most well-studied combinatorial optimization problems.
It has broad applications in logistics, planning, and DNA sequencing.
In plain words, the TSP asks the following question:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city and returns to the origin city?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Formally, for a set of cities \([n] = \{1, 2, \ldots, n \}\), an \(n\)-by-\(n\) matrix \(C = (c_{ij})\), where \(c_{ij} \geq 0 \) specifies the cost of traveling from city \(i\) to city \(j\).
By convention, we assume \(c_{ii} = 0\) and \(c_{ij} = c_{ji}\), meaning that the cost of traveling from city \(i\) to city \(j\) is equal to the cost of traveling from city \(j\) to city \(i\).
Furthermore, we only consider the &lt;strong&gt;metric TSP&lt;/strong&gt; in this article; that is,
the &lt;a href=&#34;https://en.wikipedia.org/wiki/Triangle_inequality&#34;&gt;triangle inequality&lt;/a&gt; holds for any \(i,j,k\):
$$
c_{ik} \leq c_{ij} + c_{jk}, \quad \forall i, j, k \in [n].
$$&lt;/p&gt;

&lt;p&gt;Given a permutation \(\sigma\) of \([n]\), a tour traverses the cities in the order \(\sigma(1), \sigma(2), \ldots, \sigma(n)\).
The goal is to find a tour with the lowest cost, which is equal to
$$
c_{\sigma(n) \sigma(1)} + \sum_{i=1}^{n-1} c_{\sigma(i) \sigma(i+1)}.
$$&lt;/p&gt;

&lt;h2 id=&#34;3-double-tree-algorithm&#34;&gt;3. Double-tree algorithm&lt;/h2&gt;

&lt;p&gt;We first describe a simple algorithm called the double-tree algorithm and prove that it is a 2-approximation algorithm.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Double-tree algorithm&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Find a minimum spanning tree \(T\).&lt;/li&gt;
&lt;li&gt;Duplicate the edges of \(T\). Find an Eulerian tour.&lt;/li&gt;
&lt;li&gt;Shortcut the Eulerian tour.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;Figure 1 shows the algorithm on a simple five-city instance.
We give a step-by-step explanation of the algorithm.
&lt;figure&gt;
    &lt;img src=&#34;dbl_tree.jpg&#34; alt=&#34;Double-tree algorithm&#34; width=&#34;350&#34;/&gt;
    &lt;figcaption&gt;Figure 1: Double-tree algorithm.&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/p&gt;

&lt;p&gt;A &lt;a href=&#34;https://en.wikipedia.org/wiki/Spanning_tree&#34;&gt;spanning tree&lt;/a&gt; of an undirected graph is a subgraph that is a tree and includes all of the nodes.
A &lt;a href=&#34;https://en.wikipedia.org/wiki/Minimum_spanning_tree&#34;&gt;minimum spanning tree&lt;/a&gt; of a weighted graph is a spanning tree for which the total edge cost is minimized.
There are several polynomial-time algorithms for finding a minimum spanning tree, e.g., &lt;a href=&#34;https://en.wikipedia.org/wiki/Prim%27s_algorithm&#34;&gt;Prim&amp;rsquo;s algorithm&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/Kruskal%27s_algorithm&#34;&gt;Kruskal&amp;rsquo;s algorithm&lt;/a&gt;, and the &lt;a href=&#34;https://en.wikipedia.org/wiki/Reverse-delete_algorithm&#34;&gt;reverse-delete algorithm&lt;/a&gt;.
Figure 1a shows a minimum spanning tree \(T\).&lt;/p&gt;

&lt;p&gt;There is an important relationship between the minimum spanning tree problem and the traveling salesman problem.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Lemma 1.&lt;/strong&gt; For any input to the traveling salesman problem, the cost of the optimal tour is at least the cost of the minimum spanning tree on the same input.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The proof is simple. Deleting any edge from the optimal tour results in a spanning tree, the cost of which is at least the cost of the minimum spanning tree.
Therefore, the cost of the minimum spanning tree \(T\) in Figure 1(a) is at most \( \mathrm{OPT}\).&lt;/p&gt;

&lt;p&gt;Next, each edge in the minimum spanning tree is replaced by two copies of itself, as shown in Figure 1b.
The resulting (multi)graph is Eulerian.
A graph is said to be &lt;a href=&#34;https://en.wikipedia.org/wiki/Eulerian_path&#34;&gt;Eulerian&lt;/a&gt; if there exists a tour that visits every edge exactly once.
A graph is Eulerian if and only if it is connected and each node has even degree.
Given an Eulerian graph, it is easy to construct a traversal of the edges.
For example, a possible Eulerian tour in Figure 1b is 1&amp;ndash;3&amp;ndash;2&amp;ndash;3&amp;ndash;4&amp;ndash;5&amp;ndash;4&amp;ndash;3&amp;ndash;1.
Moreover, since the edges are duplicated from the minimum spanning tree, the Eulerian tour has cost at most \(2 \, \mathrm{OPT}\).&lt;/p&gt;

&lt;p&gt;Finally, given the Eulerian tour, we remove all but the first occurrence of each node in the sequence; this step is called &lt;strong&gt;shortcutting&lt;/strong&gt;.
By the triangle inequality, the cost of the shortcut tour is at most the cost of the Eulerian tour, which is not greater than \(2 \, \mathrm{OPT}\).
In Figure 1c, the shortcut tour is 1&amp;ndash;3&amp;ndash;2&amp;ndash;4&amp;ndash;5&amp;ndash;1.
When going from node 2 to node 4 by omitting node 3, we have \(c_{24} \leq c_{23} + c_{34}\).
Similarly, when skipping nodes 4 and 3, \(c_{51} \leq c_{54} + c_{43} + c_{31}\).&lt;/p&gt;

&lt;p&gt;Therefore, we have analyzed the approximation ratio of the double-tree algorithm.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem 1.&lt;/strong&gt; The double-tree algorithm for the metric traveling salesman problem is a 2-approximation algorithm.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;4-christofides-algorithm&#34;&gt;4. Christofides&amp;rsquo; algorithm&lt;/h2&gt;

&lt;p&gt;The basic strategy of the double-tree algorithm is to construct an Eulerian tour whose total cost is at most \(\alpha \, \mathrm{OPT}\), then shortcut it to get an \(\alpha\)-approximation solution.
The same strategy can be carried out to yield a &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt;-approximation algorithm.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Christofides&amp;rsquo; algorithm&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Find a minimum spanning tree \(T\).&lt;/li&gt;
&lt;li&gt;Let \(O\) be the set of nodes with odd degree in \(T\). Find a minimum-cost perfect matching \(M\) on \(O\).&lt;/li&gt;
&lt;li&gt;Add the set of edges of \(M\) to \(T\). Find an Eulerian tour.&lt;/li&gt;
&lt;li&gt;Shortcut the Eulerian tour.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;Figure 2 illustrates the algorithm on a simple five-city instance of TSP.
&lt;figure&gt;
    &lt;img src=&#34;christofides.jpg&#34; alt=&#34;Christofides&#39; algorithm&#34; width=&#34;350&#34;/&gt;
    &lt;figcaption&gt;Figure 2: Christofides&amp;rsquo; algorithm.&lt;/figcaption&gt;
&lt;/figure&gt;&lt;/p&gt;

&lt;p&gt;The algorithm starts again with the minimum spanning tree \(T\). The reason we cannot directly find an Eulerian tour is that its leaf nodes all have degree one.
However, by the &lt;a href=&#34;https://en.wikipedia.org/wiki/Handshaking_lemma&#34;&gt;handshaking lemma&lt;/a&gt;, there is an even number of odd-degree nodes.
If these nodes can be paired up, then it becomes an Eulerian graph and we can proceed as before.&lt;/p&gt;

&lt;p&gt;Let \(O\) be the set of odd-degree nodes in \(T\).
To pair them up, we want to find a collection of edges that contain each node in \(O\) exactly once.
This is called a &lt;a href=&#34;https://en.wikipedia.org/wiki/Matching_(graph_theory)&#34;&gt;perfect matching&lt;/a&gt; in graph theory.
Given a complete graph (on an even number of nodes) with edge costs,
there is a polynomial-time algorithm to find the perfect matching of the minimum total cost, known as the &lt;a href=&#34;https://en.wikipedia.org/wiki/Blossom_algorithm&#34;&gt;blossom algorithm&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For the minimum spanning tree \(T\) in Figure 2a, \( O = \{1, 2, 3, 5\}\).
The minimum-cost perfect matching \(M\) on the complete graph induced by \(O\) is shown in Figure 2b.
Adding the edges of \(M\) to \(T\), the result is an Eulerian graph, since we have added a new edge incident to each odd-degree node in \(T\).
The remaining steps are the same as in the double-tree algorithm.&lt;/p&gt;

&lt;p&gt;We want to show that the Eulerian graph has total cost of at most &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt; \(\mathrm{OPT}\).
Since the total cost of the minimum spanning tree \(T\) is at most \(\mathrm{OPT}\), we only need to show that the perfect matching \(M\) has cost at most &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt; \(\mathrm{OPT}\).&lt;/p&gt;

&lt;p&gt;We start with the optimal tour on the entire set of cities, the cost of which is \(\mathrm{OPT}\) by definition.
Figure 3a presents a simplified illustration of the optimal tour; the solid circles represent nodes in \(O\).
By omitting the nodes that are not in \(O\) from the optimal tour, we get a tour on \(O\), as shown in Figure 3b.
By the shortcutting argument again, the total cost of the tour on \(O\) is at most \(\mathrm{OPT}\).
Next, color the edges yellow and green, alternating colors as the tour is traversed, as illustrated in Figure 3c.
This partitions the edges into two sets: the yellow set and the green set; each is a perfect matching on \(O\).
Since the total cost of the two matchings is at most \(\mathrm{OPT}\), the cheaper one has cost at most &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt; \(\mathrm{OPT}\).
In other words, there exists a perfect matching on \(O\) of cost at most &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt; \(\mathrm{OPT}\).
Therefore, the minimum-cost perfect matching must have cost not greater than &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt; \(\mathrm{OPT}\).
This completes the proof of the following theorem.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Theorem 2.&lt;/strong&gt; Christofides&amp;rsquo; algorithm for the metric traveling salesman problem is a &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt;-approximation algorithm.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;figure&gt;
    &lt;img src=&#34;matching.jpg&#34; alt=&#34;minimum-cost perfect matching&#34; width=&#34;350&#34;/&gt;
    &lt;figcaption&gt;Figure 3: Minimum-cost perfect matching.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;!-- 

## Why metric TSP?

Without the metric constraint, not only the TSP is hard, even finding an approximation algorithm for the TSP is hard.


A [Hamiltonian cycle](https://en.wikipedia.org/wiki/Hamiltonian_path) in an undirected graph is a cycle that visits each node exactly once.
It is NP-complete to decide whether a given undirected graph \\( G = (V, E) \\) has a Hamiltonian cycle.
If there were to exist a 2-approximation algorithm for the TSP, then this algorithm could be used to decide whether a Hamiltonian cycle exists.

Given an input to the Hamiltonian cycle problem \\( G = (V, E) \\), construct an input to the TSP by setting
$$
c_{ij}=
\begin{cases}
1   &amp;\mbox{if } (i, j) \in E \newline
n+2 &amp;\mbox{otherwise}
\end{cases}
$$
where \\(n = |V|\\) is the number of nodes in \\(G\\).
If the is a Hamiltonian cycle in \\(G\\), then there is a tour of cost \\(n\\); otherwise each tour costs at least \\(2n+1\\), which consists of \\(n-1\\) edges in \\(E\\) and one edge not in \\(E\\).

Run the 2-approximation algorithm on the new TSP input; 
if the computed tour has cost at most \\(2n\\), then there exists a Hamiltonian cycle in \\(G\\); otherwise, there does not.


&gt; **Theorem 3.** For any \\(\alpha &gt; 1\\), there does not exist an \\(\alpha\\)-approximation algorithm for the traveling salesman problem, provided \\(\mathrm{P} \neq \mathrm{NP}\\). --&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Williamson, D. P., &amp;amp; Shmoys, D. B. (2011). The Design of Approximation Algorithms. Cambridge University Press.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Stochastic Bandits and UCB Algorithm</title>
      <link>https://bochang.me/blog/posts/bandits/</link>
      <pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://bochang.me/blog/posts/bandits/</guid>
      <description>

&lt;p&gt;In our recent paper &lt;em&gt;Vine Copula Structure Learning via Monte Carlo Tree Search&lt;/em&gt; (AISTATS 2019), we apply the UCT (Upper Confidence bounds applied to Trees) algorithm to find an approximate solution to an NP-hard structure learning problem in statistics.
The UCT algorithm is based on the UCB1 (Upper Confidence Bound) algorithm for the stochastic bandit problem.&lt;/p&gt;

&lt;p&gt;Thankfully, I audited &lt;a href=&#34;https://www.cs.ubc.ca/~nickhar/&#34;&gt;Prof. Nick Harvey&lt;/a&gt;&amp;rsquo;s &lt;a href=&#34;https://www.cs.ubc.ca/~nickhar/F18-531/&#34;&gt;learning theory course&lt;/a&gt; this semester.
In one lecture, he gave a remarkably clear exposition of the multi-armed bandit problem and algorithms.
It deepened my understanding of the theoretical properties of the UCB1 algorithm.
This blog post is mostly a transcription of the lecture; it gives an overview of the regret bound analysis of the explore-first algorithm and UCB1 algorithm. The material is also based on the first chapter of Slivkins (2017).&lt;/p&gt;

&lt;h2 id=&#34;1-problem-formulation&#34;&gt;1. Problem formulation&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&#34;https://en.wikipedia.org/wiki/Multi-armed_bandit&#34;&gt;multi-armed bandit problem&lt;/a&gt; has many practical applications including clinical trials, financial portfolio design, and online advertising.
The name comes from imagining a gambler at a row of slot machines (sometimes known as &amp;ldquo;one-armed bandits&amp;rdquo;), each with a lever.
In each round, the gambler picks a machine to play, then the reward for the chosen machine is observed.
The objective of the gambler is to maximize the sum of rewards earned through a sequence of lever pulls.
In the rest of the post, we use the term &amp;ldquo;arm&amp;rdquo; as a synonym for a slot machine.&lt;/p&gt;

&lt;p&gt;In this post, we focus on the &lt;strong&gt;stochastic bandit problem&lt;/strong&gt;, where the rewards for each arm are i.i.d. from a probability distribution specific to that arm.
Another variant of the multi-armed bandit problem is called the &lt;strong&gt;adversarial bandit problem&lt;/strong&gt;, where an adversary chooses the reward for each arm while the player chooses an arm.&lt;/p&gt;

&lt;p&gt;The fundamental tradeoff the gambler faces is between &lt;strong&gt;exploration&lt;/strong&gt; and &lt;strong&gt;exploitation&lt;/strong&gt;.
In machine learning, exploration stands for the acquisition of new knowledge, and exploitation refers to an optimized decision based on existing knowledge.
In the case of the multi-armed bandit problem, the gambler needs to decide between trying different arms to get more information about their rewards and playing the arm that has the highest average reward so far.&lt;/p&gt;

&lt;p&gt;The following notations are used throughout the post.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;\(K\) is the total number of arms and \(T\) is the total number of rounds, both are known in advance. Arms are denoted by \(a \in [K]\), rounds by \(t \in [T]\). (The bracket notation \([n]\) denotes the first \(n\) positive integers \([n] := \{1, 2, \ldots, n\}\).)&lt;/li&gt;
&lt;li&gt;The reward for arm \(a\) is i.i.d. from \(\mathcal{D}_a\), which is a distribution supported on \([0,1]\). The expected reward of arm \(a\) is denoted by \(\mu(a) := \int_0^1 x \, \mathrm{d}\mathcal{D}_a(x)\).&lt;/li&gt;
&lt;li&gt;The best expected reward is denoted by \(\mu^* := \max_{a \in [K]} \mu(a)\), and the best arm is \(a^* = \operatorname{argmax}_{a \in [K]} \mu(a)\).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The (cumulative) &lt;strong&gt;regret&lt;/strong&gt; in round \(t\) is defined as
$$ R(t) =  \mu^* t  - \sum_{s=1}^t \mu(a_s), $$
where \(a_s\) is the chosen arm in round \(s\).
The regret is the difference between the sum of rewards associated with the optimal arm and the sum of expected rewards by an algorithm.
The goal of the algorithm is to minimize regret.
Note that \(a_s\) is a random quantity, since it may depend on the randomness in rewards and/or the algorithm.
Therefore the regret \(R(t)\) is also random and we are interested in the expected regret \(\mathbb{E}[R(t)]\) or \(\mathbb{E}[R(T)]\).&lt;/p&gt;

&lt;p&gt;It may be a good time now to review &lt;a href=&#34;https://en.wikipedia.org/wiki/Hoeffding%27s_inequality&#34;&gt;Hoeffding&amp;rsquo;s inequality&lt;/a&gt;, an important concentration inequality widely used in machine learning theory.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Hoeffding&amp;rsquo;s inequality&lt;/strong&gt;&lt;br /&gt;
Let \(X_1, \ldots, X_n\) be independent random variables and let \(\bar{X}=\frac{1}{n}\sum_{i=1}^n X_i\). Assume \(0 \leq X_i \leq 1\) almost surely. Then, for any \(t&amp;gt;0\),
$$\mathbb{P}(|\bar{X} - \mathbb{E}[\bar{X}]| &amp;gt; t) \leq 2 \exp (-2nt^2).$$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;2-explore-first-algorithm&#34;&gt;2. Explore-first algorithm&lt;/h2&gt;

&lt;p&gt;A simple idea is to explore arms uniformly and pick an empirically best arm for exploitation.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Explore-first algorithm&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Exploration phase:     Try each arm \(N\) times. Let \(\bar\mu(a)\) be the average reward for arm \(a\);&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Exploitation phase: Select arm \(\hat{a}\) with the highest average reward \(\hat{a} = \operatorname{argmax}_{a \in [K]} \bar\mu(a)\). Play arm \(\hat{a}\) in all remaining rounds.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;The parameter \(N\) is fixed in advance; it will be chosen later as a function of \(T\) and \(K\).&lt;/p&gt;

&lt;h3 id=&#34;2-1-regret-bound&#34;&gt;2.1 Regret bound&lt;/h3&gt;

&lt;p&gt;Our goal is to give an upper bound of the expected regret \(\mathbb{E}[R(T)]\) as a function of \(K\) and \(T\):
$$
\mathbb{E}[R(T)]=O \big(T^{2 / 3} (K \log T)^{1 / 3} \big).
$$&lt;/p&gt;

&lt;p&gt;To facilitate our analysis, we define the &lt;strong&gt;clean event&lt;/strong&gt; \(C\) to be the event that \(\bar\mu(a)\) is close to \(\mu(a)\) for all arms:
$$
C = \{ |\bar\mu(a) - \mu(a)| \leq r, \forall a \in [K] \},
$$
where \(r\) is called the &lt;strong&gt;confidence radius&lt;/strong&gt;.
The &lt;strong&gt;bad event&lt;/strong&gt; \(\bar{C}\) is the complement of the clean event.
By the &lt;a href=&#34;https://en.wikipedia.org/wiki/Law_of_total_expectation&#34;&gt;law of total expectation&lt;/a&gt;,
$$
\mathbb{E}[R(T)] =
\mathbb{E}[R(T) | C]
\mathbb{P}[C]
+
\mathbb{E}[R(T) | \bar{C}]
\mathbb{P}[\bar{C}].
$$&lt;/p&gt;

&lt;p&gt;First of all, we want to make sure \(\mathbb{P}[\bar{C}]\) is small.
In other words, the average reward \(\bar\mu(a)\) should be a good estimate of the true expected reward \(\mu(a)\).
By Hoeffding&amp;rsquo;s inequality, the deviation of the average reward from the true expected reward can be quantified as follows:&lt;/p&gt;

&lt;p&gt;$$
\mathbb{P}( |\bar\mu(a) - \mu(a)| &amp;gt; r) \leq 2 \exp (-2Nr^2), \quad \forall a \in [K].
$$&lt;/p&gt;

&lt;p&gt;We want to bound this probability by a sufficiently small number, say \(2/T^4\). This can be achieved by setting the confidence radius \(r = \sqrt{\frac{2 \log T}{N}}\):
$$
\mathbb{P}( |\bar\mu(a) - \mu(a)| &amp;gt; r) \leq \frac{2}{T^4}, \quad \forall a \in [K].
$$
Note that the choice of \(T^4\) is somewhat arbitrary; the exponent only affects the multiplicative constant of \(r\).&lt;/p&gt;

&lt;p&gt;Using a &lt;a href=&#34;https://en.wikipedia.org/wiki/Boole%27s_inequality&#34;&gt;union bound&lt;/a&gt;, we can find an upper bound of the probability of the bad event.
$$
\begin{align}
\mathbb{P}(\bar{C})
&amp;amp;=
\mathbb{P} \big(\{ \exists a \in [K] \ \text{s.t.}\ |\bar\mu(a) - \mu(a)| &amp;gt; r \} \big)
\newline
&amp;amp;=
\mathbb{P} \big(\bigcup_{a \in [K]}\{|\bar\mu(a) - \mu(a)| &amp;gt; r \} \big)
\newline
&amp;amp;\leq \sum_{a \in [K]} \mathbb{P} (|\bar\mu(a) - \mu(a)| &amp;gt; r )
\newline
&amp;amp;\leq
\frac{2K}{T^4}
\newline
&amp;amp;\leq
\frac{2}{T^3}.
\end{align}
$$
The last inequality is because each arm is explored at least once, i.e., \(T \geq K\).&lt;/p&gt;

&lt;p&gt;Next, we focus on \(\mathbb{E}[R(T) | C]\).
By definition, \(\bar\mu(\hat{a}) \geq \bar\mu(a^*)\).
Given the clean event happens,
an upper bound of \(\mu(a^*) - \mu(\hat{a}) \) can be obtained:
$$
\begin{align}
\mu(a^*) - \mu(\hat{a})
&amp;amp;\leq
\mu(a^*) - \mu(\hat{a}) + \bar\mu(\hat{a}) - \bar\mu(a^*)
\newline
&amp;amp;=
\big(\mu(a^*) - \bar\mu(a^*)\big) + \big(\bar\mu(\hat{a}) - \mu(\hat{a}) \big)
\newline
&amp;amp;\leq 2r.
\end{align}
$$
Intuitively, it indicates that conditioning on the clean event, the chosen arm \(\hat{a}\) cannot be much worse than \(a^*\).&lt;/p&gt;

&lt;p&gt;There are \(NK\) rounds in the exploration phase, and each round has at most regret of 1; there are \(T - NK\) rounds in the exploitation phase and the regret incurred in each round is bounded by \(2r\).
As a result, the regret in round \(T\) can be bounded by
$$
\begin{align}
\mathbb{E}[R(T) | C]
&amp;amp;\leq NK + (T - NK) 2r
\newline
&amp;amp;\leq NK + 2Tr
\newline
&amp;amp;= NK + 2T \sqrt{\frac{2 \log T}{N}}.
\end{align}
$$
Since we can choose the number of rounds in the exploration phase,
the right-hand side can be minimized by setting
\( N = (T/K)^{2 / 3} (2\log T)^{1 / 3} \).
Therefore,
$$
\mathbb{E}[R(T) | C]
\leq
T^{2 / 3} (2K\log T)^{1 / 3}.
$$&lt;/p&gt;

&lt;p&gt;So far, we have&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;\(\mathbb{E}[R(T) | C]
\leq
T^{2 / 3} (2K \log T)^{1 / 3}
\);&lt;/li&gt;
&lt;li&gt;\( \mathbb{P}[C] \leq 1 \);&lt;/li&gt;
&lt;li&gt;\( \mathbb{E}[R(T) | \bar{C}] \leq T \), since there are in total \(T\) rounds, each round incurs at most regret of 1;&lt;/li&gt;
&lt;li&gt;\(\mathbb{P}[\bar{C}] \leq 2 / T^4 \).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Putting everything together,
$$
\begin{align}
\mathbb{E}[R(T)] &amp;amp;=
\mathbb{E}[R(T) | C]
\mathbb{P}[C]
+
\mathbb{E}[R(T) | \bar{C}]
\mathbb{P}[\bar{C}]
\newline
&amp;amp;\leq
T^{2 / 3} (2K\log T)^{1 / 3}
+
T \cdot \frac{2}{T^3}
\newline
&amp;amp;= O \big(T^{2 / 3} (K \log T)^{1 / 3} \big).
\end{align}
$$&lt;/p&gt;

&lt;h2 id=&#34;3-upper-confidence-bound-algorithm&#34;&gt;3. Upper confidence bound algorithm&lt;/h2&gt;

&lt;p&gt;The problem with the explore-first algorithm is that each arm is explored for the same number of rounds, which causes inefficiency.
In other words, the exploration schedule should depend on the history of the observed rewards.
Instead of using the same confidence radius for any arm in any round, we denote the confidence radius for arm \(a\) at time \(t\) by \(r_t(a)\).
Let \(n_t(a)\) be the number of times arm \(a\) is selected in rounds \(1, 2, \ldots, t\) and \(\bar\mu_t(a)\)  be the average reward of arm \(a\) up to time \(t\).
The &lt;strong&gt;upper confidence bound&lt;/strong&gt; is defined as
$$
\mathrm{UCB}_t(a) = \bar\mu_t(a) + r_t(a),
$$
where \( r_t(a) = \sqrt{\frac{2 \log T}{n_t(a)}} \).&lt;/p&gt;

&lt;p&gt;The UCB1 algorithm chooses the best arm based on an optimistic estimate. The algorithm is as follows.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;UCB1 algorithm&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Try each arm once;&lt;/li&gt;
&lt;li&gt;In round \(t\), pick \( a_t = \operatorname{argmax}_{a \in [K]} \mathrm{UCB}_t(a)\).&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;Unlike the explore-first algorithm, there is no clear exploration/exploitation phase. However, the definition of the upper confidence bound manifests the exploration-exploitation tradeoff: \(\bar\mu_t(a)\) encourages the exploitation of high reward arms, while \(r_t(a)\) encourages the exploration of less played arms.&lt;/p&gt;

&lt;h3 id=&#34;3-1-regret-bound&#34;&gt;3.1 Regret bound&lt;/h3&gt;

&lt;p&gt;The regret bound of the UCB1 algorithm is
$$
\mathbb{E}[R(t)] = O \big(\sqrt{Kt \log T} \big),
\quad
\forall t \in [T].
$$
The idea of the analysis is the same as before: define a clean event \(C\), obtain upper bounds of \(\mathbb{P}[\bar{C}]\) and \(\mathbb{E}[R(t)|C]\), and finally bound \(\mathbb{E}[R(t)]\).&lt;/p&gt;

&lt;p&gt;Since the confidence radius now depends on \(t\) as well, we need a more refined definition of the &lt;strong&gt;clean event&lt;/strong&gt;:
$$
C = \{|\bar\mu_t(a) - \mu(a)| \leq r_t(a), \forall a \in [K], \forall t \in [T] \}.
$$
Applying Hoeffding&amp;rsquo;s inequality and a union bound (and ignoring some technicalities),
$$
\mathbb{P}[\bar{C}] \leq \frac{2KT}{T^4} \leq \frac{2}{T^2}.
$$&lt;/p&gt;

&lt;p&gt;Now we focus on \(\mathbb{E}[R(t)|C]\) and assume the clean event holds.
By definition, \( \mathrm{UCB}_t(a_t) \geq \mathrm{UCB}_t(a^*) \) for any round \(t \in [T]\).
As a result,&lt;/p&gt;

&lt;p&gt;$$
\begin{align}
\mu(a^*) - \mu(a_t)
&amp;amp;\leq
\mu(a^*) - \mu(a_t) + \mathrm{UCB}_t(a_t) - \mathrm{UCB}_t(a^*)
\newline
&amp;amp;= \big(\mu(a^*) - \mathrm{UCB}_t(a^*)\big) + \big(\mathrm{UCB}_t(a_t) - \mu(a_t) \big),
\end{align}
$$
where
$$
\mu(a^*) - \mathrm{UCB}_t(a^*)
=\mu(a^*) - \bar\mu_t(a^*) - r_t(a^*)
\leq 0,
$$
and
$$
\mathrm{UCB}_t(a_t) - \mu(a_t)
=\bar\mu_t(a_t) - \mu(a_t) + r_t(a_t)
\leq 2 r_t(a_t).
$$
Therefore,
$$
\mu(a^*) - \mu(a_t)
\leq
2 r_t(a_t)
= 2 \sqrt{\frac{2 \log T}{n_t(a_t)}}.
$$&lt;/p&gt;

&lt;p&gt;For each arm \(a\) and a given time \(t \in [T]\), consider the last round \(t_0 \leq t\) when this arm is chosen.
Since arm \(a\) is never played between round \(t_0\) and round \(t\), we have \(n_{t_0}(a) = n_t(a)\).
Applying the above inequality to arm \(a\) and round \(t_0\),
$$
\mu(a^*) - \mu(a) \leq 2 \sqrt{\frac{2 \log T}{n_t(a)}},
\quad
\forall t \in [T].
$$
Intuitively it means that, under the clean event, if an arm is selected many times, it cannot be much worse than the best arm; or equivalently, if an arm is much worse than the best arm, it won&amp;rsquo;t be selected many times.&lt;/p&gt;

&lt;p&gt;The regret in round \(t\) is thus bounded by
$$
R(t) = \sum_{a \in [K]}
n_t(a) \big(\mu(a^*) - \mu(a)\big)
\leq
2 \sqrt{2 \log T}
\sum_{a \in [K]}
\sqrt{n_t(a)}.
$$
Since the square root function is concave, by &lt;a href=&#34;https://en.wikipedia.org/wiki/Jensen%27s_inequality&#34;&gt;Jensen&amp;rsquo;s inequality&lt;/a&gt;,
$$
\sum_{a \in [K]}
\sqrt{n_t(a)}
= K \sum_{a \in [K]}
\frac{1}{K} \sqrt{n_t(a)}
\leq
K
\sqrt{\frac{1}{K}\sum_{a \in [K]} n_t(a)}
= \sqrt{Kt}.
$$
Therefore,
$$
\mathbb{E}[R(t)|C] \leq 2 \sqrt{2 Kt \log T}.
$$&lt;/p&gt;

&lt;p&gt;Finally, much like what we did for the explore-first algorithm, the expected regret in round \(t\) can be bounded by
$$
\begin{align}
\mathbb{E}[R(t)] &amp;amp;=
\mathbb{E}[R(t) | C]
\mathbb{P}[C]
+
\mathbb{E}[R(t) | \bar{C}]
\mathbb{P}[\bar{C}]
\newline
&amp;amp;\leq
2 \sqrt{2 Kt \log T}
+
t \cdot \frac{2}{T^2}
\newline
&amp;amp;= O \big(\sqrt{Kt \log T} \big),
\quad
\forall t \in [T].
\end{align}
$$&lt;/p&gt;

&lt;h3 id=&#34;3-2-an-instance-dependent-regret-bound&#34;&gt;3.2 An instance-dependent regret bound&lt;/h3&gt;

&lt;p&gt;We can also obtain another regret bound using the inequality
$$
\mu(a^*) - \mu(a) \leq 2 \sqrt{\frac{2 \log T}{n_T(a)}}.
$$
Rearrange the terms,
$$
n_T(a) \leq \frac{8 \log T}{(\mu(a^*) - \mu(a))^2},
\quad
\text{if }
\mu(a) &amp;lt; \mu(a^*).
$$
The regret in round \(T\) is bounded by
$$
R(T) = \sum_{a \in [K]} n_T(a) \big(\mu(a^*) - \mu(a)\big)
\leq
8 \log T
\sum_{\{a \in [K]: \mu(a) &amp;lt; \mu(a^*)\}}
\frac{1}{\mu(a^*) - \mu(a)}.
$$
Therefore,
$$
\mathbb{E}[R(T)]
\leq
O(\log T)
\sum_{\{a \in [K]: \mu(a) &amp;lt; \mu(a^*)\}}
\frac{1}{\mu(a^*) - \mu(a)}.
$$&lt;/p&gt;

&lt;p&gt;This regret bound is logarithmic in \(T\), with a constant that can be arbitrarily large depending on a problem instance.
This type of regret bound is called &lt;strong&gt;instance-dependent&lt;/strong&gt;. The existence of a logarithmic regret bound is a benefit of the UCB1 algorithm compared to the explore-first algorithm, whose regret bound is polynomial in \(T\).&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Slivkins, A. (2017). Introduction to Multi-Armed Bandits. &lt;a href=&#34;http://slivkins.com/work/MAB-book.pdf&#34;&gt;http://slivkins.com/work/MAB-book.pdf&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A Few LaTeX Tips</title>
      <link>https://bochang.me/blog/posts/latex/</link>
      <pubDate>Sat, 10 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://bochang.me/blog/posts/latex/</guid>
      <description>

&lt;p&gt;LaTeX is a high-quality typesetting system and the de facto standard for publication of scientific documents. However, I never got a chance to learn how to use it formally. Most of my LaTeX knowledge comes from learning by doing. As I&amp;rsquo;m working on my Ph.D. thesis, I would like to share a few LaTeX tips that I wish I had known earlier. I got most of them from working with my advisors, internship hosts, and collaborators. There is still a lot for me to learn about LaTeX. Any comments and suggestions are welcome!&lt;/p&gt;

&lt;h2 id=&#34;1-non-breaking-spaces&#34;&gt;1. Non-breaking spaces&lt;/h2&gt;

&lt;p&gt;In digital typesetting, a non-breaking space is a space character that prevents an automatic line break at its position. It is like an invisible glue between two words. There are various situations where a non-breaking space is used. For example, if the phrase &amp;ldquo;100 km&amp;rdquo; does not fit at the end of a line, the word processor may insert a line break between &amp;ldquo;100&amp;rdquo; and &amp;ldquo;km&amp;rdquo;, which is not desirable.&lt;/p&gt;

&lt;p&gt;LaTeX uses the &lt;code&gt;~&lt;/code&gt; symbol as a non-breaking space. It is usually inserted before any numeric or alphabetic reference, for example, &lt;code&gt;Figure~\ref{fig:foo}&lt;/code&gt; and &lt;code&gt;Section~\ref{sec:bar}&lt;/code&gt;. Compare the following examples:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Without a non-breaking space: &lt;code&gt;Table 3&lt;/code&gt;
&lt;img src=&#34;nonbreaking-1.png&#34; alt=&#34;without a non-breaking space&#34; /&gt;&lt;/li&gt;
&lt;li&gt;With a non-breaking space: &lt;code&gt;Table~3&lt;/code&gt;
&lt;img src=&#34;nonbreaking-2.png&#34; alt=&#34;with a non-breaking space&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;2-citations-using-citet-and-citep&#34;&gt;2. Citations using &lt;code&gt;\citet&lt;/code&gt; and &lt;code&gt;\citep&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;The &lt;code&gt;natbib&lt;/code&gt; package is commonly used for handling references in LaTeX. It is included in the style files by default for many conferences including ICML, NIPS, ICLR, etc. See &lt;a href=&#34;https://gking.harvard.edu/files/natnotes2.pdf&#34; title=&#34;Reference sheet for natbib usage&#34;&gt;here&lt;/a&gt; for a reference sheet for &lt;code&gt;natbib&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The two basic citation commands in &lt;code&gt;natbib&lt;/code&gt; are&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;\citet&lt;/code&gt; for &lt;strong&gt;textual&lt;/strong&gt; citations,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;\citep&lt;/code&gt; for &lt;strong&gt;parenthetical&lt;/strong&gt; citations.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The difference is that &lt;code&gt;\citet{jon90}&lt;/code&gt; prints &lt;em&gt;Jones et al. (1990)&lt;/em&gt;, while &lt;code&gt;\citep{jon90}&lt;/code&gt; prints &lt;em&gt;(Jones et al., 1990)&lt;/em&gt;. The choice depends on whether the authors are to be read as part of the sentence. According to the formatting instructions for ICLR 2019:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;When the authors or the publication are included in the sentence, the citation should not be in parenthesis (as in “See Hinton et al. (2006) for more information.”). Otherwise, the citation should be in parenthesis (as in “Deep learning shows promise to make progress towards AI (Bengio &amp;amp; LeCun, 2007).”).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The command &lt;code&gt;\cite&lt;/code&gt; should be avoided because its behavior depends on the citation format and might cause inconsistency. According to the &lt;code&gt;natbib&lt;/code&gt; documentation:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The standard LaTeX command &lt;code&gt;\cite&lt;/code&gt; should be avoided, because it behaves like &lt;code&gt;\citet&lt;/code&gt; for author-year citations, but like &lt;code&gt;\citep&lt;/code&gt; for numerical ones.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;3-mathematical-symbols&#34;&gt;3. Mathematical symbols&lt;/h2&gt;

&lt;p&gt;When writing mathematical formulas, people follow certain conventions of notations. In fact, there is an ISO standard &lt;a href=&#34;https://people.engr.ncsu.edu/jwilson/files/mathsigns.pdf&#34;&gt;ISO 80000-2&lt;/a&gt; that defines mathematical signs and symbols. I found an article titled &lt;a href=&#34;https://tug.org/TUGboat/tb18-1/tb54becc.pdf&#34;&gt;Typesetting mathematics for science and technology according to ISO 31/XI&lt;/a&gt; by Claudio Beccari. (ISO 31/XI is the precursor of ISO 80000-2.) The recommendations below are excerpts of the article. The &amp;ldquo;roman type&amp;rdquo; refers to upright letters and the &amp;ldquo;italic type&amp;rdquo; refers to sloping letters.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;a) Variables and functions are represented by one italic letter with modifiers such as subscripts, superscripts, primes, etc.&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;LaTeX&lt;/th&gt;
&lt;th&gt;Display&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;L(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(L(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;L&#39;(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(L&amp;rsquo;(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;L_{\mathrm{adversarial}}(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(L_{\mathrm{adversarial}}(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Incorrect&lt;/td&gt;
&lt;td&gt;&lt;code&gt;LOSS(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(LOSS(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Incorrect&lt;/td&gt;
&lt;td&gt;&lt;code&gt;Loss(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(Loss(x)\)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;b) Mathematical operators indicated with letters must be set in roman type.&lt;/strong&gt;
This includes the predefined operators &lt;code&gt;\exp&lt;/code&gt;, &lt;code&gt;\log&lt;/code&gt;, &lt;code&gt;\sin&lt;/code&gt;, &lt;code&gt;\tanh&lt;/code&gt;, &lt;code&gt;\det&lt;/code&gt;, &lt;code&gt;\min&lt;/code&gt;, &lt;code&gt;\inf&lt;/code&gt;, as well as user-defined operators.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;LaTeX&lt;/th&gt;
&lt;th&gt;Display&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;\sin(2x) = 2 \sin(x) \cos(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(\sin(2x) = 2 \sin(x) \cos(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Incorrect&lt;/td&gt;
&lt;td&gt;&lt;code&gt;sin(2x) = 2 sin(x) cos(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(sin(2x) = 2 sin(x) cos(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;\operatorname{softmax}(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(\operatorname{softmax}(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Incorrect&lt;/td&gt;
&lt;td&gt;&lt;code&gt;softmax(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(softmax(x)\)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;c) A particular operator, the operator of differentiation, should be set in roman type.&lt;/strong&gt;
This one is somewhat controversial. In some fields, italic type seems more common. I personally prefer roman type.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;LaTeX&lt;/th&gt;
&lt;th&gt;Display&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;\int x \mathrm{d} x&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(\int x \mathrm{d} x\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Incorrect&lt;/td&gt;
&lt;td&gt;&lt;code&gt;\int x dx&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(\int x dx\)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;d) Sub and superscripts that do not represent mathematical variables should be set in roman type.&lt;/strong&gt;
The first row is correct because \(n\) represents a variable here.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;LaTeX&lt;/th&gt;
&lt;th&gt;Display&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;S_n = \sum_{i=1}^n X_i&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\( S_n = \sum_{i=1}^n X_i \)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Correct&lt;/td&gt;
&lt;td&gt;&lt;code&gt;L_{\mathrm{adversarial}}(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(L_{\mathrm{adversarial}}(x)\)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Incorrect&lt;/td&gt;
&lt;td&gt;&lt;code&gt;L_{adversarial}(x)&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;\(L_{adversarial}(x)\)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;4-avoid-vspace&#34;&gt;4. Avoid &lt;code&gt;\vspace&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;Most conferences have strict page limits. More often than not, eight pages are not enough to adequately present a brilliant idea. If only Fermat got more space in the margin!&lt;/p&gt;

&lt;p&gt;A common trick is to use &lt;code&gt;\vspace&lt;/code&gt;. It can reduce the length of a vertical space before or after a section, figure or table. However, this essentially alters the style template. Many formatting instructions explicitly forbid the use of &lt;code&gt;\vspace&lt;/code&gt;. It might even result in the rejection of the paper. From the formatting instructions for AAAI 2019:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;if your paper is obviously &amp;ldquo;squeezed&amp;rdquo; it is not going to be accepted.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Reducing the vertical spaces also makes the paper less readable for the reviewers, so it is definitely not advisable.
Many conferences support the submission of supplementary material. If the paper is too long, consider reorganizing it and moving some sections to the supplementary material.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>